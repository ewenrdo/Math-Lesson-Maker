\documentclass{article}

\usepackage[a4paper, left=1.5cm, right=1.5cm, top=2cm, bottom=2cm]{geometry}

\usepackage{../../../../components/components}

\usepackage{hyperref}
\usepackage{fancyhdr}


% Configuration des en-têtes et pieds de page
\pagestyle{fancy}
\fancyhf{} % reset tout

\fancyhead[L]{DL2 Math-Info}
\fancyhead[C]{Réduction des endomorphismes}
\fancyhead[R]{2025-2026}

\fancyfoot[L]{Ewen Rodrigues de Oliveira}
\fancyfoot[R]{\thepage}

\begin{document}

\docTitle{Chapitre 6 : Théorie spectrale}


\section{Valeurs propres, vecteurs propres, sous-espaces propres}

On se donne $E$ un $K$-espace vectoriel et $u \in End(E)$ un endomorphisme de $E$.
\definition{
    Soit $\lambda \in K$. On dit que $\lambda$ est une \textbf{valeur propre (vp)} de $u$ s'il existe un vecteur $x \in E \setminus \{0_E\}$ tel que $u(x) = \lambda x$. Un tel vecteur $x$ est appelé un \textbf{vecteur propre ($\overrightarrow{vp}$)} associé à la valeur propre $\lambda$ de $u$.
}

\definition{
    On note $E_\lambda$ le \textbf{sous-espace propre} de $u$ associé à la valeur propre $\lambda$ :
    \[
        E_\lambda = \{ x \in E \mid u(x) = \lambda x \} = Ker(u - \lambda Id_E)
    \]
}

\theorem{Propriété}{}{true}{
    On a $\lambda$ est une valeur propre de $u$ si et seulement si $E_\lambda \neq \{0_E\}$.\\
    Ce qui est vrai si et seulement si $u - \lambda Id_E$ n'est pas inversible (autrement dit, $det(u - \lambda Id_E) = 0$).
}

\vocabulary{On dit que $u$ est \textbf{diagonalisable} s'il existe une base de $E$ formée de $\overrightarrow{vp}$ de $u$. (vecteurs propres)}
\theorem{Proposition}{}{false}{
    $u$ est diagonalisable si et seulement si $Mat_B(u)$ est diagonale pour une certaine base $B$ de $E$. (E de dimension finie)
}

\noindent{\textbf{Preuve :}\\
Soient $(x_1, \ldots, x_n)$ une base de $E$ formée de $\overrightarrow{vp}$ de $u$ avec $u(x_i) = \lambda_i x_i$. On a donc :
\[
    Mat_B(u) = 
    \begin{pmatrix}
        \lambda_1 & 0 & \ldots & 0 \\
        0 & \lambda_2 & \ldots & 0 \\
        \vdots & \vdots & \ddots & \vdots \\
        0 & 0 & \ldots & \lambda_n
    \end{pmatrix}
\] $\Box$
}

\vocabulary{On dit que $u$ est \textbf{trigonalisable} s'il existe une base de $E$ dans laquelle la matrice de $u$ est triangulaire supérieure. (vecteurs propres)}
\remark{Alors $x$ est un $\overrightarrow{vp}$ de $u$. Un endomorphisme sans $\overrightarrow{vp}$ n'est pas diagonalisable.}

\example{Si $E = K^2$ et $Mat_B(u) = \begin{pmatrix}
    5 & -1 \\
    4 & 1
\end{pmatrix}$ ($B$ = canonique), alors $u$ est trigonalisable pour la base $B' = \left\{ \begin{pmatrix}
    1 \\
    2   
\end{pmatrix}, \begin{pmatrix}
    0 \\
    -1
\end{pmatrix} \right\}$. En effet, on a :
$u(\begin{pmatrix}
    1 \\
    2\end{pmatrix}) = \begin{pmatrix}
    3 \\
    6
\end{pmatrix} = 3 \begin{pmatrix}
    1 \\
    2
\end{pmatrix}$
}

\example{
    Si $Mat_B(u) = \begin{pmatrix}
        1 & 1 \\
        0 & 2
    \end{pmatrix}$, alors $u$ est diagonalisable.
}
\example{
    Si $Mat_B(u) = \begin{pmatrix}
        0 & -1 \\
        1 & 0
    \end{pmatrix}$, n'est pas diagonalisable si $K = \mathbb{R}$ (pas de $\overrightarrow{vp}$), mais est diagonalisable si $K = \mathbb{C}$ (car $\lambda = i$ et $\lambda = -i$ sont des vp).
}

\section{Projections, symétries et rotations}
Posons $E = F \oplus G$ avec $F, G$ sous-espaces vectoriels de $E$.

\theorem{Proposition}{}{true}{
    Soit $p \in \mathcal{L}(E)$ la projection sur $F$ parallèlement à $G$ (i.e. $p(x + y) = x$ pour tout $(x, y) \in F \times G$).\\
    Alors les valeurs propres de $p$ sont contenues dans $\{0, 1\}$.
    De plus, $F = E_1$ et $G = E_0$ et $p$ est diagonalisable.
}

\ndlr{cf. Laurent pour la démonstration}

\theorem{Proposition}{}{true}{
    Soit $s \in \mathcal{L}(E)$ la symétrie par rapport à $F$ parallèlement à $G$ (i.e. $s(x + y) = x - y$ pour tout $(x, y) \in F \times G$).\\
    Alors les valeurs propres de $s$ sont contenues dans $\{-1, 1\}$.
    De plus, $F = E_1$ et $G = E_{-1}$ et $s$ est diagonalisable.
}

Supposons $E = \mathbb{K}^2, K=\mathbb{R}$.\\
Considérons $u$ tel que $Mat_B(u) = \begin{pmatrix}
    \cos \theta & -\sin \theta \\
    \sin \theta & \cos \theta \end{pmatrix}$ dans la base canonique $B$ de $\mathbb{R}^2$ avec $\theta \in \mathbb{R} \setminus \pi\mathbb{Z}$.

\theorem{Proposition}{}{true}{
    $u$ n'est pas diagonalisable si $K = \mathbb{R}$ (pas de $\overrightarrow{vp}$), mais est diagonalisable si $K = \mathbb{C}$ (car $\lambda = \cos \theta + i \sin \theta$ et $\lambda = \cos \theta - i \sin \theta$ sont des vp).
}

\section{Rappels sur les polynômes}
\ndlr{cf. AL2}

\definition{
    Un polynôme $P$ est irréductible sur $K$ si $P=QR$ entraine que $Q$ ou $R$ est de degré $0$ (c'est-à-dire une constante).\\
    Cela dépend du corps $K$.
}

\definition{
    $P$ est sciendé sur $K$ si $P$ est produit de polynômes de degré $1$ sur $K$.
}
\example{
    Sur $\mathbb{R}$, $X^2 + 1$ est irréductible. Sur $\mathbb{C}$, $X^2 + 1 = (X - i)(X + i)$ est scindé.
}

\vocabulary{$P$ est scindé à racines simples si $P$ est scindé et si toutes ses racines sont de multiplicité $1$, i.e. $P = c(X - \alpha_1)(X - \alpha_2) \ldots (X - \alpha_n)$ avec $\alpha_i$ distincts.}

\theorem{Théorème d'Alembert-Gauss}{}{true}{
    \begin{enumerate}
        \item Si $K = \mathbb{C}$, tout polynôme de degré $\geq 1$ est scindé. (i.e. $\mathbb{C}$ est un corps algébriquement clos)
        \item Si $K = \mathbb{R}$, tout polynôme de degré $\geq 1$ est produit de polynômes irréductibles de degré $1$ ou $2$.
    \end{enumerate}
}

\section{Polynôme caractéristique d'un endomorphisme}

Soit $E$ un $K$-espace vectoriel de dimension finie $n$ et $u \in End(E)$.\\
\reminder{Soit $\lambda \in K$. C'est une valeur propre de $u$ si et seulement si $det(u - \lambda Id_E) = 0$.}
\example{
    $Mat_B(u) = \begin{pmatrix}
        5 & 1 \\
        2 & 4 \end{pmatrix}$. $E=\mathbb{R}^2$, $K=\mathbb{R}$ et $B$ la base canonique.\\
        On a :
    \[
    det(u - \lambda Id_E) = det\begin{pmatrix}
        5 - \lambda & 1 \\
        2 & 4 - \lambda
    \end{pmatrix} = \lambda^2 - 9\lambda + 18 = (\lambda - 6)(\lambda - 3)
    \]
    Donc les valeurs propres de $u$ sont $3$ et $6$.
}

\theorem{Théorème}{}{true}{
    Posons $P_u(\lambda) = det(\lambda Id_E - u)$. C'est un polynôme de $K[\lambda]$ de degré $n$ appelé \textbf{polynôme caractéristique} de $u$.\\
    Plus précisément, on a $P_u(\lambda) = (-1)^n \lambda^n + (-1)^{n-1} tr(u) \lambda^{n-1} + \ldots + det(u)$.
}
\example{
    Pour $n=2$, on a $P_u(\lambda) = \lambda^2 - tr(u) \lambda + det(u)$.\\
}

\theorem{Corollaire}{}{true}{
    L'endomorphisme $u$ admet au plus $n$ valeurs propres (distinctes).
}

\section{Polynôme caractéristique d'une matrice}

Soit $A \in M_n(K)$ une matrice carrée, soit $\lambda \in K$.
On dit que $\lambda$ est une valeur propre de $A$ s'il existe un vecteur $X \in K^n \setminus \{0\}$ tel que $AX = \lambda X$.
On pose $E_{\lambda}(A) = Ker(A - \lambda I_n)$ le sous-espace propre de $A$ associé à la valeur propre $\lambda$.
Et on pose $P_A(\lambda) = det(\lambda I_n - A)$ le polynôme caractéristique de $A$.

\theorem{Proposition}{}{true}{
    Soit $AB \in M_n(K)$ tel que $B$ sont semblables $A$ (i.e. il existe $P \in GL_n(K)$ tel que $B = P^{-1}AP$).\\
    Alors $A$ et $B$ ont même polynôme caractéristique ($P_A = P_B$) et donc les mêmes valeurs propres.
}

\theorem{Proposition}{}{true}{
    Supposons $A$ triagonalisable (i.e. semblable à une matrice triangulaire).\\
    Alors $P_A$ est scindé sur $K$.
}

\remark{La réciproque est vraie (vu plus tard), $P_A$ scindé $\implies A$ trigonalisable.}
\attention{Retenir que $P_A$ non scindé $\implies A$ non trigonalisable.}

\example{
    Si $K=\mathbb{R}$ et $A = \begin{pmatrix}
        0 & 1 \\
        0 & 0
    \end{pmatrix}$. On a $P_A(\lambda) = \lambda^2$. Mais $A$ n'est pas diagonalisable.
}

\section{Étude des sous-espaces propres (sep)}

Soit $E$ un $K$-espace vectoriel de dimension finie $n$ et $u \in End(E)$.
Soit $F$ un sev de $E$.

\definition{
    On dit que $F$ est \textbf{stable} par $u$ si $u(F) \subset F$.
    Alors $u_{|F} \in End(F)$ est la restriction de $u$ à $F$.
}

\theorem{Proposition}{}{true}{
    Le polynôme caractéristique de $u_{|F}$ divise celui de $u$.
    Autrement dit : $P_{u_{|F}}(\lambda) | P_u(\lambda)$.\\
    Autrement dit : $\exists Q \in K[\lambda], P_u(\lambda) = P_{u_{|F}}(\lambda) Q(\lambda)$.
}

\textit{La preuve utilise le déterminant par blocs.}

\theorem{Proposition}{}{true}{
    Soit $k \leq n$ et soient $A \in M_k(K)$ et $B \in M_{k,n-k}(K)$ et $D \in M_{n-k}(K)$.\\
    On a : $det\begin{pmatrix}
        A & B \\
        0 & D\end{pmatrix} = det(A) det(D)$.
}

\theorem{Proposition}{}{true}{
    Soit $\lambda \in K$. Alors $E_\lambda$ est stable par $u$.
}
En effet, si $u(x) = \lambda x$, alors $u(u(x)) = u(\lambda x) = \lambda u(x)$, donc $u(x) \in E_\lambda$.

\theorem{Corollaire}{}{true}{
    Soit $\lambda \in K$, et soit $X \in E_\lambda \setminus \{0_E\}$.\\
On a que $u_{|E_\lambda}$ est une homothétie de rapport $\lambda$.\\
Donc $P_{u_{|E_\lambda}}(\lambda) = (\lambda - X)^{\dim(E_\lambda)}$\\.
En particulier, $P_{u_{|E_\lambda}}$ divise $P_u$.\\
}

\vocabulary{On appelle la \textbf{multiplicité} de la valeur propre $\lambda$ pour $u$ le plus grand entier $m$ tel que $(\lambda - X)^m$ divise $P_u(X)$. On la note $m_{a}(\lambda)$.}
\vocabulary{On appelle la \textbf{multiplicité géométrique} de la valeur propre $\lambda$ pour $u$ l'entier $\dim(E_\lambda)$. On la note $m_{g}(\lambda)$.}

\theorem{Proposition}{}{true}{
    On a $1 \leq m_{g}(\lambda) \leq m_{a}(\lambda)$ si $\lambda$ est une valeur propre de $u$.
}

\example{
    Soit $A = \begin{pmatrix}
        3 & 0 & 0 \\
        0 & 3 & 1 \\
        0 & 0 & 3
    \end{pmatrix}$. On a $P_A(\lambda) = (3 - \lambda)^3$. Donc $m_a(3) = 3$.\\
    On a $E_3 = Ker(A - 3I_3) = \left\{ \begin{pmatrix}
        x \\
        y \\
        0
    \end{pmatrix} \mid (x, y) \in K^2 \right\}$. Donc $\dim(E_3) = 2$. Donc $m_g(3) = 2$.
}

\theorem{Proposition}{Somme directe des sep}{true}{
    Soit $\lambda_1, \lambda_2, \ldots, \lambda_k$ des valeurs propres distinctes de $u$.\\
    Alors $E_{\lambda_1} + E_{\lambda_2} + \ldots + E_{\lambda_k}$ est une somme directe.\\
    i.e. $\sum_{i=1}^k E_{\lambda_i} = \bigoplus_{i=1}^k E_{\lambda_i}$.\\\\
    Autrement dit, les sous-espaces propres associés à des valeurs propres distinctes sont en somme directe.
}

\theorem{Corollaire}{}{true}{
    Toute famille de vecteurs propres associés à des valeurs propres distinctes est libre.
}
\theorem{Corollaire}{}{true}{
    Si $u$ admet $n$ valeurs propres distinctes (avec $n = \dim(E)$), alors $u$ est diagonalisable.
}
\example{
    Soit $A = \begin{pmatrix}
        1 & 2 & 3 \\
        2 & 4 & 6 \\
        3 & 6 & 9
    \end{pmatrix}$. On a $P_A(\lambda) = -\lambda(\lambda^2 - 15\lambda -18)$ qui est scindé sur $\mathbb{R}$ à racines simples. Les valeurs propres sont $0, \frac{15 + \sqrt{297}}{2}, \frac{15 - \sqrt{297}}{2}$, donc distinctes. Donc $A$ est diagonalisable.
}

\section{Diagonalisabilité}

Soit $E$ un $K$-espace vectoriel de dimension finie $n$ et $u \in End(E)$.
Soit $F$ un sev de $E$.

\theorem{Théorème}{}{true}{
    $u$ est diagonalisable si et seuelemnt si $E = \bigoplus_{\lambda \text{ vp de } u} E_\lambda$.\\\\

    Autrement dit, $u$ est diagonalisable si et seulement si la somme des dimensions des sous-espaces propres de $u$ est égale à $\dim(E)$.\\
}

\theorem{Théorème}{}{true}{
    $u$ est diagonalisable si et seulement si le polynôme caractéristique de $u$ est scindé et on a $m_a(\lambda) = m_g(\lambda)$ pour toute valeur propre $\lambda$ de $u$.
}

\theorem{Proposition}{}{true}{
    Supposons $u$ diagonalisable. Soit $F$ un sev de $E$ stable par $u$.\\
    Alors la restriction $u_{|F} \in \mathcal{L}(F)$ est diagonalisable.
}

\theorem{Lemme}{}{true}{
    On a $F = \bigoplus_{\lambda \text{ vp de } u} (F \cap E_\lambda)$.
}

\theorem{Théorème}{}{true}{
    Soit $v \in End(E)$ tel que $u \circ v = v \circ u$ (i.e. $u$ et $v$ commutent).\\
    Supposons que $u$ et $v$ sont diagonalisables.\\
    Alors il existe une base $B$ de $E$ telle que les matrices de $u$ et $v$ dans cette base sont diagonales. 
}

\vocabulary{On dit que $u$ et $v$ sont \textbf{simultanément diagonalisables}.}

\theorem{Corollaire}{}{true}{
    Soit $v \in End(E)$ tel que $u \circ v = v \circ u$ (i.e. $u$ et $v$ commutent).\\
    Alors toute combinaison linéaire de $u$ et $v$ est diagonalisable.\\
    De plus, $u \circ v$ et $v \circ u$ sont diagonalisables.
}

\section{Trigonalisation}

\theorem{Théorème}{}{true}{
    $u$ est trigonalisable si et seulement si le polynôme caractéristique de $u$ est scindé.
}

\theorem{Corollaire}{}{true}{
    Si $K = \mathbb{C}$, tout endomorphisme de $E$ est trigonalisable.
}

\example{Soit $\theta \in \mathbb{R} \setminus \pi \mathbb{Z}$ et $u$ tel que $Mat_B(u) = \begin{pmatrix}
    \cos \theta & -\sin \theta \\
    \sin \theta & \cos \theta
\end{pmatrix}$ dans la base canonique $B$ de $\mathbb{R}^2$.\\
On a $P_u(\lambda) = \lambda^2 - 2\cos \theta \lambda + 1$. Ce polynôme n'est pas scindé sur $\mathbb{R}$ car ses racines sont $\cos \theta \pm i \sin \theta$. Donc $u$ n'est pas trigonalisable sur $\mathbb{R}$. Cependant, $P_u$ est scindé sur $\mathbb{C}$, donc $u$ est trigonalisable sur $\mathbb{C}$.
}

\section{Polynômes d'endomorphismes (et de matrices)}
Soit $K$ un corps. Soit $E$ un $K$-espace vectoriel. Soit $P \in \mathbb{K}[X]$, $P = P(X) = \sum_{k=0}^d a_k X^k$ (où $d$ est le degré de $P$).
Soit $u \in End(E)$ un endomorphisme de $E$, et $u \circ u = u^2$.
En particulier, on a $u \circ u \circ \ldots \circ u = u^k$ ($k$ fois), $u^0 = Id_E$ et $u^1 = u$.\\\\
\definition{
    On pose $P(u) = \sum_{k=0}^d a_k u^k \in End(E)$. C'est un polynôme en $u$.\\
    L'application \function{\varphi_u}{K[X] \to End(E)}{P \mapsto P(u)} est linéaire.\\
    On note $\mathbb{K}[u] = Im(\varphi_u) = \{ P(u) \mid P \in K[X] \}$. C'est un sous-espace vectoriel de $End(E)$.
}

\definition{
    Soit $A \in M_n(K)$. On définit de même $P(A) = a_0I_n + a_1A + \cdots + a_d A^d = \sum_{k=0}^d a_k A^k \in M_n(K)$.\\
    L'application \function{\psi_A}{K[X] \to M_n(K)}{P \mapsto P(A)} est linéaire.\\\\

    Si $A = Mat_B(u)$, alors $P(A) = Mat_B(P(u))$.\\
    On note $\mathbb{K}[A] = Im(\psi_A) = \{ P(A) \mid P \in K[X] \}$. C'est un sous-espace vectoriel de $M_n(K)$.
}

\theorem{Proposition}{Stabilité du noyau}{true}{
    Le sous-espace vectoriel $Ker(P(u))$ est stable par $u$.
}

\remark{Si $u,v \in End(E)$, on a $Ker(v)$ est stable par u. Or $P(u)$ et $u$ commutent.}
\remark{Plus généralement, pour $P,Q \in K[X]$, on a $P(u)$ et $Q(u)$ commutent.}
\noindent{\textbf{Preuve :}\\
Si $Q = b_0 + b_1 X + \ldots + b_e X^e$, alors $P(u) \circ Q(u) = Q(u) \circ P(u)$ car :
\begin{align*}
    P(u) \circ Q(u) &= \left( \sum_{k=0}^d a_k u^k \right) \circ \left( \sum_{l=0}^e b_l u^l \right) \\
    &= \sum_{k=0}^d \sum_{l=0}^e a_k b_l u^{k+l} \\
    &= \sum_{l=0}^e \sum_{k=0}^d b_l a_k u^{l+k} \\
    &= Q(u) \circ P(u)
\end{align*} $\Box$
}

\theorem{Proposition}{}{true}{
    Si $\lambda \in Sp(u)$, alors $P(\lambda) \in Sp(P(u))$.
}

\remark{Il peut exister $\lambda \in K$ tq $P(\lambda) \in Sp(P(u))$ mais $\lambda \notin Sp(u)$.}
\cexample{
    $u = id_E, P(X)=X^2-1, \lambda = -1$.
    On a $Sp(u) = \{1\}$, mais $P(-1) = 0 \in Sp(P(u))$.
    Mais $-1 \notin Sp(u)$.
}

\vocabulary{On dit que $P$ est un polynôme annulateur de $u$ si $P(u) = 0_{End(E)}$.}
\theorem{Proposition}{Sous-groupe des polynômes annulateurs}{true}{
    Considérons $Ann_{\mathbb{K}[X]}(u) = \{ P \in K[X] \mid P(u) = 0 \}$ l'ensemble des polynômes annulateurs de $u$.\\
    C'est un sous-groupe de $(K[X], +)$.\\\\
    De plus, pour $Q \in K[X]$ et $P \in Ann_{\mathbb{K}[X]}(u)$, on a $Q P \in Ann_{\mathbb{K}[X]}(u)$.
}
\vocabulary{On dit que $Ann_{\mathbb{K}[X]}(u)$ est un idéal de l'anneau $K[X]$. (HP)}
\noindent{\textbf{Preuve du sous groupe :}\\
Soient $P, Q \in Ann_{\mathbb{K}[X]}(u)$. On a :
\begin{itemize}
    \item $P + Q \in Ann_{\mathbb{K}[X]}(u)$ car $(P + Q)(u) = P(u) + Q(u) = 0 + 0 = 0$.
    \item $-P \in Ann_{\mathbb{K}[X]}(u)$ car $(-P)(u) = -P(u) = -0 = 0$.
    \item $0 \in Ann_{\mathbb{K}[X]}(u)$ car $0(u) = 0$.
\end{itemize} $\Box$
}

\noindent{\textbf{Preuve de la stabilité par multiplication :}\\
Soit $P \in Ann_{\mathbb{K}[X]}(u)$ et $Q \in K[X]$. On a :
\[
    (Q P)(u) = Q(u) \circ P(u) = Q(u) \circ 0 = 0
\]
$\Box$
}

\theorem{Proposition}{Unicité du polynôme}{true}{
    Il existe un unique $P_0 \in \mathbb{K}[X]$ unitaire (i.e. de coefficient dominant $a_d = 1$) tel que $P \in Ann_{\mathbb{K}[X]}(u) \Leftrightarrow \exists Q : P = Q P_0$. En particulier, $P_0 \in Ann_{\mathbb{K}[X]}(u)$ et $P_0$ divise tout polynôme annulateur de $u$.\\
    On a : $P_0 = \prod_{i} (X-\lambda_i)^{m_g(\lambda_i)}$.
}

\vocabulary{$P_0$ est appelé le \textbf{polynôme minimal} de $u$. C'est le polynôme annulateur de $u$ unitaire de plus petit degré.}

\theorem{Proposition}{}{true}{
    Si $\lambda$ est une valeur propre de $u$ et $P \in Ann_{\mathbb{K}[X]}(u)$, alors $P(\lambda) = 0$.\\\\
    Autrement dit, toute valeur propre de $u$ est racine de son polynôme minimal.
}

\example{
    Soit $u$ une homothétie de rapport $\lambda \in K$.\\
    On a $P(u) = 0 \Leftrightarrow a_0 I_E + a_1 u + \ldots + a_d u^d = 0 \Leftrightarrow P(\lambda) id_E = 0 \Leftrightarrow P(\lambda) = 0 \Leftrightarrow (X - \lambda) | P$.\\
    Donc le polynôme minimal de $u$ est $P_0(X) = X - \lambda$.
}
\example{
    $E = \mathbb{R}^3$
    $Mat_{B,C}(u) = \begin{pmatrix}
        1 & 1 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & 1
    \end{pmatrix}$ dans les bases $B, C$ canoniques.\\
    $(X-1)^2$ annule u car $Mat_{B,C}(u - Id_E) = \begin{pmatrix}
        0 & 1 & 0 \\
        0 & 0 & 0 \\
        0 & 0 & 0
    \end{pmatrix}$ et donc ($u - Id_E)^2 = 0$.\\
    Donc le polynôme minimal de $u$ divise $(X-1)^2$ ou $(X-1)$.\\
    Or $u \neq Id_E$, donc le polynôme minimal de $u$ est $P_0(X) = (X-1)^2$.
}

Pour $A \in M_n(K)$, on définit de même le polynôme minimal de $A$.

\definition{
Soient $P_1, P_2 \in K[X]$. On dit que $P_1$ et $P_2$ sont \textbf{premiers entre eux} s'il existe $Q_1, Q_2 \in K[X]$ tels que $Q_1 P_1 + Q_2 P_2 = 1$. \\\\

De même, pour $m$ polynômes, on a : $P_1, P_2, \ldots, P_m$ sont premiers entre eux s'il existe $Q_1, Q_2, \ldots, Q_m \in K[X]$ tels que $\sum_{i=1}^m Q_i P_i = 1$.\\
Cela entraine qu'ils n'ont pas de facteur commun non constant (i.e. de degré $\geq 1$).
}

\definition{
    Soit $P_1, \ldots P_m \in K[X]$. On dit que $P_1, \ldots, P_m$ sont \textbf{premiers entre eux deux à deux} si pour tout $i \neq j$, $P_i$ et $P_j$ sont premiers entre eux.
}

\theorem{Théorème}{Lemme des noyaux}{true}{
    Soit $u \in End(E)$ et soient $P_1, P_2, \ldots, P_m \in K[X]$ des polynômes deux à deux premiers entre eux et tous non nuls.\\
    Posons $ P = \prod_{i=1}^m P_i$.
    Alors on a :
    \[
        Ker\left( P(u) \right) = \bigoplus_{i=1}^m Ker\left( P_i(u) \right)
    \]\\\\
    En particulier, si $P \in Ann_{\mathbb{K}[X]}(u)$ on a $E = \bigoplus_{i=1}^m Ker\left( P_i(u) \right)$.
    Si $\pi_i$ est la projection de $E$ sur $Ker\left( P_i(u) \right)$ parallèlement aux autres $Ker\left( P_j(u) \right)$ ($j \neq i$), alors $\pi_i \in \mathbb{K}[u]$ et $\sum_{i=1}^m \pi_i = Id_E$.
}

\theorem{Théorème}{}{true}{
    $u$ est diagonalisable ssi. $u$ admet un polynôme annulateur scindé à racines simples.
}

\section{Matrices compagnons et théorème de Cayley-Hamilton}

Soit $P \in K[X]$ unitaire.
Posons $P(X) = a_0 + a_1 X + a_2X^2 + ... + a_{n-1}X^{n-1} + X^n$.

\definition{On appelle \textbf{matrice compagnon} de $P$ la matrice :
\[
C(P) = 
\begin{pmatrix}
0      & 0      & 0      & \cdots & 0      & -a_0 \\
1      & 0      & 0      & \cdots & 0      & -a_1 \\
0      & 1      & 0      & \cdots & 0      & -a_2 \\
0      & 0      & 1      & \cdots & 0      & -a_3 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0      & 0      & 0      & \cdots & 1      & -a_{\,n-1}
\end{pmatrix}.
\]

}
\theorem{Proposition}{}{true}{
    Le polynôme caractéristique de $A$ est $(-1)^nP(X)$.
}

Soit $E$ un $K$-espace vectoriel de dimension $n$.
Soit $u \in \mathcal{L}(E)$. Notons $P_u$ son polynôme caractéristique.

\theorem{Théorème de Cayley-Hamilton}{}{true}{
    On a $P_u(u)=0$.\\
    Autrement dit, le polynôme minimal de $u$ divise $P_u$.
}

\example{
    On prend $n=2$.
    Alors $P_u(X)=X^2-Tr(u)X+det(u)$.
    Donc $u^2-Tr(u)\cdot u + detu=0$.
}

\theorem{Corollaire}{}{true}{
    $u \in GL(E) \Leftrightarrow det(u) \neq 0$.\\
    Dans ce cas, on a $u^{-1} \in K[u]$.
}

\section{Sous espaces caractéristiques}


Soit $E$ un $K$-espace vectoriel de dimension finie $n$.\\
Soit $u \in \mathcal{L}(E)$ un endomorphisme de $E$.\\
Soit $\lambda \in K$ une valeur propre de $u$.\\
\reminder{On appelle $m_a(\lambda)$ la multiplicité algébrique de $\lambda$, c'est-à-dire la multiplicité de $\lambda$ comme racine du polynôme caractéristique de $u$.}
\reminder{On appelle $m_g(\lambda)$ la multiplicité géométrique de $\lambda$, c'est-à-dire la dimension du sous-espace propre $E_\lambda = Ker(u - \lambda Id_E)$.}

\definition{
    On pose $N_\lambda = Ker\big((u - \lambda Id_E)^{m_a(\lambda)}\big)$.\\
    Il s'agit du \textbf{sous-espace caractéristique} de $u$ associé à la valeur propre $\lambda$.
}

\theorem{Théorème}{}{true}{
    On suppose $P_u$ scindé (i.e. trigonalisable).\\
    Alors :
    \begin{enumerate}
        \item $N_\lambda$ est un sev stable par $u$ de dimension $m_a(\lambda)$.
        \item $E_\lambda \subset N_\lambda$.
        \item $E = \bigoplus_{\lambda \in Sp(u)} N_\lambda$.
        \item Soit $\pi_\lambda$ la projection de $E$ sur $N_\lambda$ parallèlement à $\bigoplus_{\mu \in Sp(u), \mu \neq \lambda} N_\mu$.\\
        Alors $\pi_\lambda \in K[u]$.
        \item Si $\lambda \neq \mu$, $\pi_\lambda \circ \pi_\mu = 0$
    \end{enumerate}
}

\example{
    $Mat(u) = \begin{pmatrix}
        1 & 1 & 0\\
        0 & 1 & 0\\
        0 & 0 & 2
    \end{pmatrix}$. Les valeurs propres sont $1$ et $2$.
    $P_u(X) = -(X-1)^2(X-2)$.\\
    Donc :
    \begin{itemize}
        \item $\lambda = 2$, $m_a(2)=m_g(1)=1$ donc $E_2 = Ke_3 = N_2$.
        \item $\lambda = 1$, $m_a(1)=2$ et $m_g(1)=1$ donc $E_1 = Ke_1$ et $N_1 = Ke_1 \oplus Ke_2$.
    \end{itemize}
}

\theorem{Théorème}{}{true}{
    $N_\lambda$ est stable par $u$ et posons $u_\lambda = u_{|N_\lambda}$.\\
    Alors : 
    \begin{enumerate}
        \item $u_\lambda$ a une seule valeur propre qui est $\lambda$.
        \item On a $P_u = \pm (X - \lambda)^{m_a(\lambda)}$.
        \item On a $dim N_\lambda = m_a(\lambda)$.
        \item $\exists B_\lambda$ une base de $N_\lambda$ telle que $Mat_{B_\lambda}(u_\lambda) = \lambda I_{m_a(\lambda)}$.
    \end{enumerate}
}

\theorem{Corollaire}{}{true}{
    On suppose $P_u$ scindé.\\
    Il existe une base $B$ de trigonalisation de $u$ telle que la $Mat_B(u)$ est de la forme suivante :\\
% Forme bloc-triangulaire : blocs diagonaux A_{lambda_k}
\[
\mathrm{Mat}_B(u) =
\begin{pmatrix}
A_{\lambda_1} & 0            & \cdots & 0 \\
0             & A_{\lambda_2} & \ddots & \vdots \\
\vdots        & \ddots       & \ddots & 0 \\
0             & \cdots       & 0      & A_{\lambda_k}
\end{pmatrix},
\]
\[
\text{avec}\qquad
A_{\lambda_i} =
\begin{pmatrix}
\lambda_i & \ast      & \ast & \cdots & \ast\\
0         & \lambda_i & \ast & \cdots & \ast\\
\vdots    & \ddots    & \ddots & \ddots & \vdots\\
0         & \cdots    & 0      & \lambda_i & \ast\\
0         & \cdots    & \cdots & 0      & \lambda_i
\end{pmatrix}
\]
}

\example{
    $E = \mathbb{R}^3$ et $u$ tel que $Mat(u) = \begin{pmatrix}
        2 & 1 & 3\\
        5 & 3 & 6\\
        -2 & -1 & -2\end{pmatrix}$.\\
    $P_u(X) = - (X-1)^3$.\\
    Donc $1$ est la seule valeur propre de $u$ avec $m_a(1)=3$.\\
    Or $u$ n'est pas diagonalisable car si $u$ diagonalisable dans $B$, on a $Mat_B(u) = I_3$ .
    Donc $u = Id_E$. Absurde.\\\\
    $u$ est scindé, donc trigonalisable.
}


\section{Nilpotence}

\definition{
    On dit que $u \in End(E)$ est \textbf{nilpotent} s'il existe $k \in \mathbb{N}^*$ tel que $u^k = 0_{End(E)}$.
}
\vocabulary{On appelle l'indice de nilpotence le plus petit entier $k$ tel que $u^k = 0$.}

\theorem{Proposition}{}{true}{
    L'endomorphisme $u$ est nilpotent si et seulement si $P_u$ est scindé avec pour seule racine $0$ (c'est à dire que sa seule valeur propre est $0$).\\
    En particulier, $u$ est trigonalisable strictement avec des 0 sur la diagonale. On a que l'indice de nilpotence de $u$ est inférieur ou égal à $dim(E)$.
}
\theorem{Corollaire}{}{true}{
    $u$ nilpotent et diagonalisable $\Rightarrow u = 0_{End(E)}$.
}

\theorem{Proposition}{}{true}{
    Si $u$ est nilpotent d'indice $k$ et $x \in E$ avec $u^{k-1}(x) \neq 0$, alors la famille $\{x, u(x), u^2(x), \ldots, u^{k-1}(x)\}$ est libre.\\
    Ainsi, on a $k \leq dim(E)$.
}

\theorem{Proposition}{}{true}{
    Si $u$ est nilpotent d'indice $n = dim(E)$, alors il existe une base $B$ de $E$ telle que :
    \[
    Mat_B(u) =
    \begin{pmatrix}
        0 & 1 & 0 & \cdots & 0\\
        0 & 0 & 1 & \cdots & 0\\
        \vdots & \vdots & \ddots & \ddots & \vdots\\
        0 & 0 & \cdots & 0 & 1\\
        0 & 0 & \cdots & 0 & 0
    \end{pmatrix}
    \]
}

\remark{
    La matrice ci-dessus est un cas particulier de forme de Jordan.
}
\remark{\textbf{Comment trouver une base de trigonalisation de $u$ lorsque $u$ est nilpotent d'indice $k \leq n=dim(E)$ ?}\\
    On a $Ker(u) \subset Ker(u^2) \subset \cdots \subset Ker(u^{k-1}) \subsetneq Ker(u^k) = E$.\\
    On considère $B_1$ une base de $Ker(u)$, que l'on complète en une base $B_2$ de $Ker(u^2)$, que l'on complète en une base $B_3$ de $Ker(u^3)$, et ainsi de suite jusqu'à obtenir une base $B_k$ de $E$.\\
    On a ainsi construit une base $B_k$ de $E$ telle que $Mat_{B_k}(u)$ est triangulaire supérieure avec des 0 sur la diagonale.\\
}

\theorem{Proposition}{Combinaison linéaire}{true}{
    Soient $u,v \in End(E)$ deux endomorphismes nilpotents qui commutent.\\
    Alors toute combinaison linéaire $au + bv$ avec $a,b \in K$ est nilpotente.
}

\section{Décomposition de Jordan Chévalley (ou Dunford)}

\theorem{Théorème}{}{true}{
    Soit $u \in End(E)$ tel que $P_u$ est scindé.\\
    Il existe un unique $(d,e) \in End(E)^2$ tel que :
    \begin{itemize}
        \item $u = d + e$,
        \item $d$ est diagonalisable,
        \item $e$ est nilpotent,
        \item $d$ et $e$ commutent.
        \item $d,e \in K[u]$ (polynômes en $u$).
    \end{itemize}.\\
    C'est la \textbf{décomposition de Jordan Chévalley} (ou Dunford) de $u$.
}

\definition{
    Soit $A \in M_n(K)$.\\
    On dit que $A$ est nilpotente si il existe $k \geq 1$ tel que $A^k = 0$ (matrice nulle).
}

\theorem{Théorème}{Décomposition de Jordan Chévalley matricielle}{true}{
    Soit $A \in M_n(K)$ tel que son polynôme caractéristique est scindé.\\
    Il existe un unique couple $(D,N) \in M_n(K)^2$ tel que :
    \begin{itemize}
        \item $A = D + N$,
        \item $D$ est diagonalisable,
        \item $N$ est nilpotente,
        \item $D$ et $N$ commutent,
        \item $D,N$ sont des polynômes en $A$.
    \end{itemize}
}


\example{
    Soit $A = \begin{pmatrix}
        3 & -1 & 1\\
        2 & 0 & 1\\
        1 & -1 & 2
    \end{pmatrix}$.\\
    On calcule facilement que :
    \begin{itemize}
        \item $P_A(X) = -(X-2)^2(X-1)$,
        \item $m_a(2) = 2$, $m_g(2) = 1$,
        \item $m_a(1) = m_g(1) = 1$.
        \item $E_2 = Ker(A - 2I_3) = Vect\{(1,1,0)^T\}$,
        \item $N_1 = E_1 = = Ker(A - I_3) = Vect\{(0,1,1)^T\}$.
        \item $N_2 = Ker\big((A - 2I_3)^2\big) = Vect\{(1,1,0)^T, (0,0,1)^T\}$.
    \end{itemize}
    On a donc $N_1 + N_2 = \mathbb{R}^3$. (car $dim(N_1) + dim(N_2) = 3$ et $N_1 \cap N_2 = \{0\}$).\\
    Donc $N_1 \oplus N_2 = \mathbb{R}^3$.\\
    Par le théorème de Jordan Chévalley, il existe un unique $(D,N)$ tel que $A = D + N$ avec $D$ diagonalisable, $N$ nilpotente et $DN = ND$.\\
    Or :
    \begin{itemize}
        \item $d(e_1) = 2e_1 + e_2 + e_3$
        \item $d(e_2) = e_2 - e_2$
        \item $d(e_3) = 2e_3$
    \end{itemize}
    Donc $D = Mat_{can}d = \begin{pmatrix}
        2 & 1 & 0\\
        1 & 1 & 1\\
        1 & 0 & 1
    \end{pmatrix}$ et $N = A - D = \begin{pmatrix}
        1 & -1 & 1\\
        1 & -1 & 1\\
        0 & 0 & 0
    \end{pmatrix}$.\\
    De plus, $N^2 = 0_3$. Donc $N$ est nilpotente d'indice $2$.
    Donc : $A = \begin{pmatrix}
        2 & 1 & 0\\
        1 & 1 & 1\\
        1 & 0 & 1
    \end{pmatrix} + \begin{pmatrix}
        1 & -1 & 1\\
        1 & -1 & 1\\
        0 & 0 & 0
    \end{pmatrix}$ : décomposition de Jordan Chévalley de $A$.\\\\
    \textbf{Pour calculer $A^n$ :}\\
    On utilise le fait que $D$ et $N$ commutent, le binôme de Newton donc et la nilpotence de $N$ :
    \[A^n = (D + N)^n = \sum_{k=0}^{n} \binom{n}{k} D^{n-k}N^k = D^n + nD^{n-1}N\] (tous les termes avec $k \geq 2$ sont nuls car $N^2 = 0$).
}
\end{document}
