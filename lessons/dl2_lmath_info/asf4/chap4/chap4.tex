\documentclass{article}

\usepackage[a4paper, left=1.5cm, right=1.5cm, top=2cm, bottom=2cm]{geometry}

\usepackage{../../../../components/components}
\usepackage{hyperref}
\usepackage{fancyhdr}


% Configuration des en-têtes et pieds de page
\pagestyle{fancy}
\fancyhf{} % reset tout

\fancyhead[L]{DL2 Math-Info ASF4}
\fancyhead[C]{Algèbre}
\fancyhead[R]{2025-2026}

\fancyfoot[L]{Ewen Rodrigues de Oliveira}
\fancyfoot[R]{\thepage}

\begin{document}

\docTitle{Chapitre 4 : Espaces euclidiens}
\section{Produit scalaire et norme}
\subsection{Produit scalaire}
\textit{On ne rappelera pas les définitions de normes et distances ici et les propositions qui s'ensuivent. Le lecteur est invité à se référer au chapitre 4 du cours AN3.}

\definition{
    Soit $E$ un $\mathbb{R}$-espace vectoriel.\\
    Un \textbf{produit scalaire} sur $E$ est une application $\langle \cdot, \cdot \rangle : E \times E \to \mathbb{R}$ qui vérifie les propriétés suivantes :
    \begin{enumerate}
        \item $\forall x,y \in E, \; \langle x,y \rangle = \langle y,x \rangle$ (symétrie)
        \item $\forall x,x',y \forall \lambda \in \mathbb{R}, \; \langle \lambda x + x', y \rangle = \lambda \langle x,y \rangle + \langle x',y \rangle$ (linéarité en la première variable)
        \item $\forall x \in E, \; \langle x,x \rangle \geq 0$ et $\langle x,x \rangle = 0 \Rightarrow x = 0$ (positivité)
    \end{enumerate}
    En résumé, un produit scalaire est une forme bilinéaire, symétrique et définie positive.
}

\example{
    Dans $\mathbb{R}^n$,$\langle x,y \rangle = \sum_{i=1}^n x_i y_i$ est un produit scalaire.\\
    Dans $\mathcal{C}^0([0,1],\mathbb{R})$, $\langle f,g \rangle = \int_0^1 f(t)g(t) dt$ est un produit scalaire.
}

\remark{Si $E$ est un espace vectoriel normé de dimension finie, il n'y a pas de produit scalaire canonique \textit{a priori}. (On a vu néanmoins que dans $\mathbb{R}^n$, il existe un produit scalaire canonique.}

\definition{
    Un $\mathbb{R}$-espace vectoriel $E$ muni d'un produit scalaire est appelé un \textbf{espace euclidien}.\\
    On le note $(E, \langle \cdot, \cdot \rangle)$.
}

\theorem{Identités remarquables}{}{false}{
    $\langle x+y, x+y \rangle = \langle x,x \rangle + 2\langle x,y \rangle + \langle y,y \rangle$\\
    $\langle x+y, x-y \rangle = \langle x,x \rangle - \langle y,y \rangle$\\
}

\theorem{Théorème}{Inégalité de Cauchy-Schwarz}{false}{
    Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien.\\
    Alors, pour tous $x,y \in E$, on a :
    \[
        |\langle x,y \rangle| \leq \sqrt{\langle x,x \rangle} \sqrt{\langle y,y \rangle}
    \]
    De plus, l'égalité a lieu si et seulement si $x$ et $y$ sont colinéaires.
}

\noindent{ \textbf{Démonstration :}\\
    \begin{itemize}
        \item   Soit $t\in\mathbb{R}$. On pose $P(t)=\langle x, y\rangle$. Supposons $y\ne0$.\\
                $P(t)=\langle x, x\rangle+2t\langle x, y\rangle+t^2\langle y, y\rangle\ge0$ est polynômiale de degré 2 si $y\ne0$. Ainsi $\Delta\le0$.\\
                $\Delta=(2\langle x, y\rangle)^2-4\langle x, x\rangle\langle y, y\rangle=4(\langle x, y\rangle^2-\langle x, x\rangle\langle y, y\rangle)$. Donc $\langle x, y\rangle\le\langle x, x\rangle\langle y, y\rangle$.
        \item   Supposons l'égalité. Alors $\Delta=0$. Soit $t_0\in\mathbb{R}$ tel que $P(t_0)=0$.\\
                On obtient $\langle x+ty, x+ty\rangle=0$, c'est-à-dire que $x+t_0y=0$. Donc $x$ et $y$ sont colinéaires.
        \item   Réciproquement, si $x$ et $y$ sont colinéaires.\\
                Si $y\ne0$, on peut écrire $x=\lambda y$ et $|\langle x, y\rangle|=|\langle\lambda y, y\rangle|=|\lambda|\langle y, y\rangle$.\\
                $\sqrt{\langle x, x\rangle}=\sqrt{\langle\lambda y, \lambda y\rangle}=\sqrt{\lambda^2\langle y, y\rangle}=\lambda\langle y, y\rangle$. D'où l'égalité. $\Box$
    \end{itemize}
}

\subsection{Normes}

\reminder{On rappelle qu'une norme est une application $N\colon E \to \mathbb{R}_+$ qui vérifie l'homogénéité, l'inégalité triangulaire et la séparation.}

\theorem{Proposition}{}{false}{
    Soit $E$ un $\mathbb{R}$-espace vectoriel, muni d'un produit scalaire $\langle \cdot, \cdot \rangle$.\\
    On pose $\| x \| = \sqrt{\langle x,x \rangle}$.\\
    Alors $\| \cdot \|$ est une norme sur $E$, appelée la norme associée au produit scalaire $\langle \cdot, \cdot \rangle$.
}

\noindent{\textbf{Démonstration :}\\
\textbf{Homogénéité :} Soit $\lambda \in \mathbb{R}$ et $x \in E$.\\
$\| \lambda x \| = \sqrt{\langle \lambda x, \lambda x \rangle} = \sqrt{\lambda^2 \langle x,x \rangle} = |\lambda| \sqrt{\langle x,x \rangle} = |\lambda| \| x \|$\\
\textbf{Inégalité triangulaire :} Soit $x,y \in E$.\\
$\| x+y \|^2 = \langle x+y, x+y \rangle = \langle x,x \rangle + 2\langle x,y \rangle + \langle y,y \rangle \leq \langle x,x \rangle + 2|\langle x,y \rangle| + \langle y,y \rangle$\\
$\leq \langle x,x \rangle + 2\sqrt{\langle x,x \rangle} \sqrt{\langle y,y \rangle} + \langle y,y \rangle = (\sqrt{\langle x,x \rangle} + \sqrt{\langle y,y \rangle})^2$\\
$\Rightarrow \| x+y \| \leq \| x \| + \| y \|$\\
\textbf{Séparation :} Soit $x \in E$ tel que $\| x \| = 0$.\\
Alors $\sqrt{\langle x,x \rangle} = 0 \Rightarrow \langle x,x \rangle = 0 \Rightarrow x = 0$\\
}

\remark{$x \mapsto |x|$ est une norme sur $\mathbb{R}$, associée au produit scalaire $\langle x,y \rangle = xy$.}
\reminder{Une distance sur un ensemble $X$ est une application $d : X \times X \to \mathbb{R}_+$ qui vérifie la séparation, la symétrie et l'inégalité triangulaire.}

\theorem{Proposition}{Lien entre norme et distance}{false}{
    Soit $N$ une norme sur un $\mathbb{R}$-espace vectoriel $E$.\\
    Alors $d(x,y) = N(x-y)$ est une distance sur $E$.
}

\remark{En géométrie affine, si $A$ et $B$ sont deux points, le vecteur $\overrightarrow{AB}$ est défini par $\overrightarrow{AB} = B - A$, et $d(A,B) = \| \overrightarrow{AB} \|$.}

\remark{Un produit scalaire donne une norme ($\| x \| = \sqrt{\langle x,x \rangle}$) et une norme donne une distance ($d(x,y) = \| x-y \|$).}
\theorem{Propriété}{Norme associée au produit scalaire (identité du parallélogramme)}{false}{
    $\forall x,y \in E, \; \| x + y \|^2 + \| x - y \|^2 = 2\| x \|^2 + 2\| y \|^2$. \\
    On peut le vérifier avec $\| x \| = \sqrt{\langle x,x \rangle}$ et les identités remarquables.\\\\
    D'où si une norme ne vérifie pas l'identité du parallélogramme, elle n'est pas associée à un produit scalaire.
}
\noindent{ \textbf{Démonstration :}\\
    Vérifions avec $\|x\|=\sqrt{\langle x, x\rangle}$.\\
    $\|x+y\|^2=\|x\|^2+2\langle x, y\rangle+\|y\|^2$ et $\|x-y\|^2=\|x\|^2-2\langle x, y\rangle+\|y\|^2$.\\
    Donc, $\|x+y\|^2+\|x-y\|^2=2(\|x\|^2+\|y\|^2)$.
}

\definition{
    Soit $E$ un $\mathbb{R}$-espace vectoriel, muni d'un produit scalaire $\langle \cdot, \cdot \rangle$.\\
    L'\textbf{angle non-orienté} entre $x,y \in E\setminus \{0\}$ est défini par $\theta = \arccos\left(\frac{\langle x,y \rangle}{\| x \| \| y \|}\right) \in [0, \pi]$.
}

\remark{Cette définition est basée sur la propriété en géométrie euclidienne classique (angle où la direction n'a pas d'importance), et on a : $\langle x,y \rangle = \| x \| \| y \| \cos(\theta)$.}
\remark{Le vecteur normé associé à $x \in E\setminus \{0\}$ est $\frac{x}{\| x \|}$. C'est utile pour calculer des vecteurs unitaires.}

\section{Orthogonalité}
\subsection{Vecteurs orthogonaux, familles orthogonales et orthonormées}
\definition{
    Soit $E$ un $\mathbb{R}$-espace vectoriel, muni d'un produit scalaire $\langle \cdot, \cdot \rangle$.\\
    Deux vecteurs $x,y \in E$ sont dits \textbf{orthogonaux} si $\langle x,y \rangle = 0$.\\\\
    On note $x \perp y$. De même, si $F$ est un sous-espace vectoriel de $E$, on dit que $x \perp F$ si $\forall y \in F, \; x \perp y$.
}
\remark{L'angle entre deux vecteurs orthogonaux non nuls est $\frac{\pi}{2}$, et tout vecteur est orthogonal au vecteur nul.}

\definition{
    Soit $E$ un $\mathbb{R}$-espace vectoriel, muni d'un produit scalaire $\langle \cdot, \cdot \rangle$.\\
    Une famille de vecteurs $(x_i)_{i \in I}$ est dite \textbf{orthogonale} si $x_i \perp x_j$ pour tous $i \neq j$, \textit{i.e.} si ses vecteurs sont deux à deux orthogonaux.
}

\theorem{Théorème de Pythagore}{}{false}{
    Soit $E$ un $\mathbb{R}$-espace vectoriel, muni d'un produit scalaire $\langle \cdot, \cdot \rangle$.\\
    Soit $(x_1, \ldots, x_k)$ une famille orthogonale (finie) de $E$.\\
    Alors : \[ \| x_1 + \ldots + x_k \|^2 = \| x_1 \|^2 + \ldots + \| x_k \|^2. \]
    De plus, si $k=2$, alors $\| x + y \|^2 = \| x \|^2 + \| y \|^2 \Rightarrow x \perp y$.
}

\noindent{\textbf{Démonstration :}\\
$\| \sum_{i=1}^k x_i \|^2 = \langle \sum_{i=1}^k x_i, \sum_{j=1}^k x_j \rangle = \text{ (bilinéarité) } \sum_{i=1}^k \sum_{j=1}^k \langle x_i, x_j \rangle = \sum_{i=1}^k \langle x_i, x_i \rangle = \sum_{i=1}^k \| x_i \|^2$.\\\\
Pour $k = 2$, 
$\| x + y \| ^ 2 = \|x\|^2 + 2\langle x,y \rangle + \| y \|^2$.\\
Donc si $\| x + y \|^2 = \| x \|^2 + \| y \|^2$, alors $2\langle x,y \rangle = 0 \Rightarrow x \perp y$. $\Box$
}

\definition{
    Soit $E$ un $\mathbb{R}$-espace vectoriel, muni d'un produit scalaire $\langle \cdot, \cdot \rangle$.\\
    Une famille de vecteurs $(x_i)_{i \in I}$ est dite \textbf{orthonormée} si elle est orthogonale et que $\| x_i \| = 1$ pour tout $i \in I$.\\\\
    Autrement dit, $\forall i,j \in I, \; \langle x_i, x_j \rangle = \delta_{ij}$.
}

\theorem{Proposition}{}{false}{
    Soit $E$ un $\mathbb{R}$-espace vectoriel, muni d'un produit scalaire $\langle \cdot, \cdot \rangle$.\\
    Alors une famille orthogonale dont chacun des vecteurs est non nul est libre.\\\\En particulier, une famille orthonormée est libre.
}

\remark{Si $E$ est de dimension finie, toute famille orthonormée admet au plus $\dim(E)$ vecteurs.}

\noindent{ \textbf{Démonstration :}\\
    Soit $\sum_{i\in J}\lambda_ix_i=0$ une combinaison linéaire nulle de vecteur de la famille $J$, avec $J\subset I$ un ensemble fini. \\
    Soit $j\in J$, $\langle x_j, \sum_{i\in J}\lambda_ix_i\rangle=0$.\\
    D'où $\sum_{i\in J}\lambda_i\langle x_j, x_i\rangle=0$ car $ \langle x_j, x_i\rangle=0$ si $i\ne j$.\\
    D'où $\lambda_j\langle x_i, x_j\rangle=0$; $\langle x_j, x_i\rangle>0$ car $x_j\ne0$.
    D'où $\lambda_j=0$. D'où $\forall j\in J$, $\lambda_j=0$.\\
    Donc $(x_i)_{i\in I}$ est libre.
}

\definition{
    Soit $E$ un espace euclidien.\\
    Une \textbf{base orthonormée} de $E$ est une famille orthonormée qui est une base de $E$.
}

\textbf{Parenthèse : avantages d'une base orthonormée :}\\
Soit $(e_1, \ldots, e_n)$ une base orthonormée de $E$.\\
Soit $x \in E$.\\

\noindent Alors : $x = \sum_{i=1}^n \langle x, e_i \rangle e_i$. (on remarque que ça ressemble à la dualité !)\\
La $i^{ème}$ coordonnée de $x$ dans la base $(e_1, \ldots, e_n)$ est $\langle x, e_i \rangle$.\\

\subsection{Procédé d'orthonormalisation Gram-Schmidt}

\href{https://www.youtube.com/watch?v=TeIZSCzyDjA}{Voir cette vidéo pour une explication du procédé d'orthonormalisation Gram-Schmidt.}\\

%On obtient l'algorithme suivant :\\
%Soit $(e_1, \ldots, e_n)$ une base de $E$.
%On pose $u_1 = \frac{e_1}{\| e_1 \|}$.\\
%Si $(u_1, \ldots, u_{k})$ est construite pour $k \leq n - 1$, on pose $u_{k+1} = \frac{e_{k+1} - \sum_{i=1}^{k} \langle e_{k+1}, u_i \rangle u_i}{\| e_{k+1} - \sum_{i=1}^{k} \langle e_{k+1}, u_i \rangle u_i \|}$.

\theorem{Théorème}{}{false}{
    Soit $E$ un espace euclidien de dimension finie et soit $(e_1, \ldots, e_k)$ une famille libre de $E$.\\
    Il existe une famille $(u_1, \ldots, u_k)$ orthonormée de $E$ telle que $\forall i \in S_k, \; \text{Vect}(u_1, \ldots, u_i) = \text{Vect}(e_1, \ldots, e_i)$.\\
    En particulier, si $k = \dim(E)$, alors $(u_1, \ldots, u_k=u_n)$ est une base orthonormée de $E$.
}

\noindent{\textbf{Démonstration :}\\
On procède par récurrence sur $k$.\\
\textbf{Initialisation :} $k=1$.\\
Alors $(e_1)$ est une famille libre de $E$ si et seulement si $e_1 \neq 0$.\\
Dans ce cas, on pose $u_1 = \frac{e_1}{\| e_1 \|}$, qui est un vecteur de norme 1.\\
\textbf{Hérédité :} Supposons que la propriété est vérifiée pour $k \leq n-1$.\\
Soit $(e_1, \ldots, e_{k+1})$ une famille libre de $E$.\\
Par hypothèse de récurrence, il existe une famille $(u_1, \ldots, u_k)$ orthonormée de $E$ telle que $\forall i \in S_k, \; \text{Vect}(u_1, \ldots, u_i) = \text{Vect}(e_1, \ldots, e_i)$.\\
On pose : $\overline{u_{k+1}} = e_{k+1} - \sum_{i=1}^{k} \langle e_{k+1}, u_i \rangle u_i$.\\

Soit $1 \leq i \leq k$.\\
On a : $\langle \overline{u_{k+1}}, u_i \rangle = \langle e_{k+1}, u_i \rangle - \sum_{j=1}^{k} \langle e_{k+1}, u_j \rangle \underbrace{\langle u_j, u_i \rangle}_{\delta{ij}}$. (car $(u_1, \ldots, u_k)$ est orthonormée)\\
$\langle \overline{u_{k+1}}, u_j \rangle = \langle e_{k+1}, u_i \rangle - \langle e_{k+1}, u_i \rangle = 0$.\\
De plus, $\overline{u_{k+1}} \neq 0$ car $e_{k+1} \notin \text{Vect}(e_1, \ldots, e_k) = \text{Vect}(u_1, \ldots, u_k)$.\\
On pose alors $u_{k+1} = \frac{\overline{u_{k+1}}}{\| \overline{u_{k+1}} \|}$, qui est un vecteur de norme 1.\\
On a : $(u_1, \ldots, u_{k+1})$ est une famille orthonormée de $E$ qui vérifie $\forall i \in S_{k+1}, \; \text{Vect}(u_1, \ldots, u_i) = \text{Vect}(e_1, \ldots, e_i)$. $\Box$
}

\theorem{Corollaire}{}{false}{
    Tout espace euclidien de dimension finie admet une base orthonormée.
}

\definition{
    Soient $E, F$ deux espaces euclidiens.\\
    On appelle \textbf{isométrie} de $E$ dans $F$ toute application $f : E \to F$ qui est un isomorphisme d'espace vectoriel et $\forall x \in E, \; \| f(x) \| = \| x \|$.
}
\remark{$\forall x \in E \; \| f(x) \| = \| x \| \Leftrightarrow \forall x,y \in E, \; \langle f(x), f(y) \rangle = \langle x,y \rangle$.}
\training{Démontrer la remarque précédente.}
\noindent\carreaux{10}

\definition{
    Deux espaces euclidiens $E$ et $F$ sont dits \textbf{isométriques} s'il existe une isométrie de $E$ dans $F$.
}

\theorem{Théorème}{}{false}{
    Soit $E$ un espace euclidien de dimension $n$.\\
    Alors $E$ est isométrique à $\mathbb{R}^n$ muni du produit scalaire canonique.
}

\noindent{\textbf{Démonstration :}\\
Soit $(e_1, \ldots, e_n)$ une base orthonormée de $E$.\\
Soit $(\varepsilon_1, \ldots, \varepsilon_n)$ la base canonique de $\mathbb{R}^n$.\\
On définie l'application linéaire $f : E \to \mathbb{R}^n$ par $f(e_i) = \varepsilon_i$ pour tout $i \in S_n$.\\
Alors $f$ est un isomorphisme d'espace vectoriel (car l'image d'une base est une base).\\\\
Soit $x,y \in E$.\\
$x = \sum_{i=1}^n x_i e_i$ et $y = \sum_{i=1}^n y_i e_i$ avec $x_i, y_i \in \mathbb{R}$.\\
$\langle x,y \rangle = \langle \sum_{i=1}^n x_i e_i, \sum_{j=1}^n y_j e_j \rangle = \sum_{i=1}^n \sum_{j=1}^n x_i y_j \langle e_i, e_j \rangle$ (bilinéarité)\\
$= \sum_{i=1}^n x_i y_i$ (car $(e_1, \ldots, e_n)$ est orthonormée) qui est le produit scalaire canonique de $f(x) = \sum_{i=1}^n x_i \varepsilon_i$ et $f(y) = \sum_{i=1}^n y_i \varepsilon_i$.\\
$= \langle f(x), f(y) \rangle$ (car $f(x) = \sum_{i=1}^n x_i \varepsilon_i$ et $f(y) = \sum_{i=1}^n y_i \varepsilon_i$)\\
$\Rightarrow f$ est une isométrie de $E$ dans $\mathbb{R}^n$. $\Box$
}

\subsection{Projections orthogonales}

\definition{
    Soit $E$ un espace euclidien et soit $F$ un sous-espace vectoriel de $E$.\\
    Alors :
    \begin{enumerate}
        \item $\forall x \in E \; \exists ! y \in F : (x-y) \perp F$. On dit que $y$ est le \textbf{projeté orthogonal} de $x$ sur $F$.
        \item L'application $p : E \to F$ qui à $x$ associe son projeté orthogonal sur $F$ est appelée \textbf{projection orthogonale} de $E$ sur $F$ et $ker(p) = \{ z \in E : z \perp F \} = F^\perp$. On a de plus que $p$ est un projecteur (\textit{i.e.} $p^2 = p$).
    \end{enumerate}
}

\noindent{\textbf{Démonstration de l'unicité du projeté orthogonal :}\\
Soit $y$ tel que $y \in F$ et $x - y \perp F$.\\
$F$ est un espace euclidien en posant comme produit scalaire sur $F$ la restriction à $F \times F$ du produit scalaire de $E$.\\
Soit $(e_1, \ldots, e_k)$ une base orthonormée de $F$.\\
Alors : $y = \sum_{i=1}^k \langle y, e_i \rangle e_i$ et on a de plus $\forall i \in S_n \; e_i \perp x - y$.\\
Donc $0 = \langle x-y, e_i \rangle = \langle x, e_i \rangle - \langle y, e_i \rangle$ donc $y = \sum_{i=1}^k \langle x, e_i \rangle e_i$. $\Box$
}

\noindent{\textbf{Démonstration de l'existence du projeté orthogonal :}\\
Le vecteur $y = \sum_{i=1}^k \langle x, e_i \rangle e_i$ vérifie bien $y \in F$ et $x-y \perp F$. $\Box$
}

\noindent{\textbf{Démonstration de $ker(p)$ :}\\
$ker p = \{ z \in E : p(z) = 0 \} = \{ z \in E : z \perp F \} = F^\perp$. $\Box$
}

\remark{Soit $p$ la projection orthogonale sur $F$. Alors pour $x \in E, \; p(x)$ est l'unique vecteur de $F$ tel que $\| x - p(x) \| = \min_{z \in F} \| x - z \|$. Autrement dit, $p(x)$ est le point de $F$ le plus proche de $x$.} 
\noindent{ \textbf{Démonstration :}\\
    On a $\|x-z\|^2=\|x-p(x)+p(x)-z\|^2=\|x-p(x)\|^2\|p(x)-z\|^2$ par Pythagore.\\
    $\ge\|x-p(x)\|^2$. Donc $p(x)$ atteint le $\min_{z\in F}\|x-z\|$.\\
    De plus, le minimum est unique car $\|x-z\|=\min{z\in F}\|x-z\|\Rightarrow\|p(x)-z\|=0\Rightarrow p(x)=z$.
}

\ndlr{cf. Laurent pour ce qui s'ensuit (fait). cf. OneNote pour le schéma.}
\remark{On peut retrouver la formule de la distance d'un point à une droite / plan dans $\mathbb{R}^3$. Prendre une base orthonormée du plan $P$ et $d(x, P) = \| x - \sum_{i=1}^2 \langle x, e_i \rangle e_i \|$ où $d(x, F) = \inf_{y \in F} \| x - y \|$.}

\remark{Si $(e_1, \ldots, e_k)$ est une famille libre de $E$. Gram-Schmit définit par récurrence $u_1 = \frac{e_1}{\| e_1 \|}$ et $u_{k+1} = \frac{e_{k+1} - p_i(e_{k+1})}{\| e_{k+1} - p_i(e_{k+1}) \|}$, où $p_i$ est la projection orthogonale sur $\text{Vect}(u_1, \ldots, u_k)$.}

\subsection{Suppléments orthogonaux}

\definition{
    Soit $E$ un espace euclidien. Soit $F$ un sous-espace vectoriel de $E$.\\
    On note \[F^\perp = \{ x \in E \mid \forall y \in F, \; \langle x,y \rangle = 0 \} = \bigcap_{y \in F} ker(x \mapsto \langle x,y \rangle) = \bigcap_{i \in S_k} ker(x \mapsto \langle x,e_i \rangle)\]
    où $(e_1, \ldots, e_k)$ est une base de $F$. $F^\perp$ est appelé l'\textbf{espace orthogonal} de $F$ dans $E$.
}

\remark{
    $x \perp F \Leftrightarrow x \in F^\perp$.
}

\theorem{Théorème}{}{false}{
    Soit $E$ un espace euclidien de dimension finie et soit $F$ un sous-espace vectoriel de $E$.\\
    Alors $E = F \oplus F^\perp$ (c'est même une somme directe orthogonale) et $F = (F^\perp)^\perp$.
}

\noindent{\textbf{Démonstration :}\\
$F^\perp = ker p$ et $F = Im p$ où $p$ est la projection orthogonale de $E$ sur $F$.\\
D'où $F^\perp \oplus F = ker p \oplus Im p = E$.\\
On a $dim(F^\perp)^\perp = dim(E) - dim(F^\perp) = dim(F)$ donc il suffit de montrer une inclusion.\\
Soit $y \in F^\perp$.\\
Alors $\forall x \in F, \; \langle y,x \rangle = 0$ (en effet, si $x \in F$ alors $\forall y \in F^\perp, \; \langle y,x \rangle = 0$)\\
D'où $F \subset (F^\perp)^\perp$, d'où $F^\perp \supset (F^\perp)^\perp$. $\Box$
}

\theorem{Corollaire}{}{false}{
    Soit $H$ un hyperplan de $E$. Alors il existe $x_0 \in E$ tel que $H = (Vect(x_0))^\perp$.
}
\noindent{\textbf{Démonstration :}\\
Par définition d'un hyperplan, et comme $H^\perp$ est un supplémentaire de $H$, il existe $x_0 \in H^\perp$ tel que $H^\perp = Vect(x_0)$.\\
Et donc $H = (H^\perp)^\perp = (Vect(x_0))^\perp$. $\Box$
}

\remark{Si $A \subset E$, on définit $A^\perp = \{ x \in E : \forall a \in A, \; \langle x,a \rangle = 0 \}$.\\
Alors $A^\perp$ est un sev de $E$ et $A^\perp = (Vect(A))^\perp$.}

\training{Montrer que $F_1 \subset F2 \Rightarrow F_2^\perp \subset F_1^\perp$.}
\noindent\carreaux{10}

\section{Dual d'espace euclidien}


\theorem{Théorème}{Représentation des formes linéaires}{false}{
    Soit $E$ un espace euclidien. On note $j_E : E \to E^*$ l'application qui à $x$ associe $j_E(x) : y \mapsto \langle x,y \rangle$.\\
    Alors $j_E$ est un isomorphisme d'espace vectoriel de $E$ dans $E^*$.\\\\
    Autrement dit, $\forall \varphi \in E^*, \; \exists x \in E : \varphi = \langle x, \cdot \rangle$.
}
\noindent{\textbf{Démonstration :}\\
$j_E$ est linéaire et $dimE = dimE^*$ et $x \in ker(j_E) \Leftrightarrow \forall y \in E, \; \langle x,y \rangle = 0 \Leftrightarrow x = 0$. $\Box$
}

\remark{Si $\varphi \in E^*, y \in E$ on a le crochet de dualité $\langle \varphi, y \rangle$. Mais aussi si $x$ est tel que $\varphi = \langle x, \cdot \rangle$, on a aussi $\langle x, y \rangle = \langle \varphi, y \rangle$. Donc on peut confondre les deux crochets de dualité. Autrement dit, $\langle j_E(x), y \rangle_{E^* \times E} = \langle x, y \rangle_{E \times E}$ et $j_E$ permet de dire que le crochet de dualité est la même chose que le produit scalaire en identifiant $E$ et $E^*$ de manière canonique.}

\section{Cas des $\mathbb{C}$-espaces vectoriels : espaces hermitiens}

\definition{
    Soit $E$ un $\mathbb{C}$-espace vectoriel.\\
    Soit $\langle \cdot, \cdot \rangle : E \times E \to \mathbb{C}$ une application.\\
    On dit que $\langle \cdot, \cdot \rangle$ est un \textbf{produit scalaire} sur $E$ si :
    \begin{enumerate}
        \item $\forall x,y \in E, \; \langle x,y \rangle = \overline{\langle y,x \rangle}$ (hermitianité)
        \item $\forall x\in E \; y \mapsto \langle x,y \rangle$ est $\mathbb{C}$-linéaire (linéarité en la seconde variable)
        \item $\forall x \in E, \; \langle x,x \rangle > 0$ si $x\neq 0$ et $\langle x,x\rangle = 0$ si $x=0$ (positivité)
    \end{enumerate}
}

\remark{Sesquilinéaire : $\forall y \in E \forall x, x' \in E \lambda \in \mathbb{C} \; \langle \lambda x + x', y \rangle = \overline{\lambda} \langle x,y \rangle + \langle x',y \rangle$. $\forall x \in E \forall y,y' \in E \forall \lambda \in \mathbb{C} \; \langle x, \lambda y + y' \rangle = \lambda \langle x,y \rangle + \langle x,y' \rangle$.}

\example{Dans $\mathbb{C}^n$, $x = (x_i)$ et $y = (y_i)$, $\langle x,y \rangle = \sum_{i=1}^n  \overline{x_i} y_i$ est un produit scalaire (canonique).}
\remark{Pour $n = 1$, $x,y \in \mathbb{C}$, $\langle x,y \rangle = \overline{x} y$ est un produit scalaire, et $\langle x, x \rangle = |x|^2$ (module au carré).}

\remark{}
$
\begin{cases}
    y \mapsto \langle x,y \rangle \text{ est } \mathbb{C}\text{-linéaire} \\
    \forall x,y \in E,\;
    \langle x,y \rangle = \overline{\langle y,x \rangle}
    \text{ (hermitianité)}
\end{cases}
$
implique que $(x,y) \mapsto \langle x,y \rangle$ est sesquilinéaire.

\remark{
    Dans $\mathcal{C}^0([a,b], \mathbb{C})$, $\langle f, g \rangle = \int_a^b \overline{f}(t) g(t) dt$ est un produit scalaire.
}

\definition{
    On appelle \textbf{espace hermitien} un $\mathbb{C}$-espace vectoriel muni d'un produit scalaire (complexe/hermitien).
}

\definition{
    Soit $E$ un espace hermitien.\\
    On appelle \textbf{famille orthonormée} de $E$ une famille de vecteurs normées qui sont deux à deux orthogonaux, c'est à dire $(e_1, \ldots, e_k)$ telle que $\forall i,j \in S_k, \; \langle e_i, e_j \rangle = \delta_{ij}$.
}

\remark{Le théorème de Pythagore reste vérifié dans les espaces hermitiens.}
\attention{La réciproque du même théorème ($\langle x,y \rangle = 0 \Rightarrow \| x+y \|^2 = \| x \|^2 + \| y \|^2$) n'est pas vérifiée dans les espaces hermitiens.}

\theorem{Proposition}{}{false}{
    Si $(e_1, \ldots, e_n)$ est une base orthonormée de $E$ un espace hermitien, et on a $x = \sum_{i=1}^n x_i e_i$ et $y = \sum_{j=1}^n y_j e_j$, alors :
    \[
    x_i = \langle x, e_i \rangle \text{ et } y_j = \langle y, e_j \rangle
     \text{ et } \langle x,y \rangle = \sum_{i=1}^n \overline{x_i} y_i
    \]
}

\theorem{Théorème}{Inégalité de Cauchy-Schwarz dans les espaces hermitiens}{false}{
    Soit $E$ un espace hermitien de dimension finie (et son produit scalaire complexe).\\
    Alors $\forall x,y \in E, \; |\langle x,y \rangle| \leq \sqrt{\langle x,x \rangle} \sqrt{\langle y,y \rangle}$
}

\theorem{Corollaire}{}{false}{
    Si $E$ est un $\mathbb{C}$-espace vectoriel muni d'un produit scalaire complexe, alors $\| x \| = \sqrt{\langle x,x \rangle}$ est une norme sur $E$.
}

\training{Proposer une démonstration de l'inégalité de Cauchy-Schwarz dans les espaces hermitiens.}
\noindent\carreaux{10}


\newpage
\tableofcontents


\end{document}  