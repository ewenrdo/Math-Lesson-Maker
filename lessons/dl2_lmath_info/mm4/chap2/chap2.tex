\documentclass{article}

\usepackage[a4paper, left=1.5cm, right=1.5cm, top=2cm, bottom=2cm]{geometry}

\usepackage{../../../../components/components}

\usepackage{fancyhdr}


% Configuration des en-têtes et pieds de page
\pagestyle{fancy}
\fancyhf{} % reset tout

\fancyhead[L]{DL2 Math-Info MM4}
\fancyhead[C]{Algèbre linéaire}
\fancyhead[R]{2025-2026}

\fancyfoot[L]{Ewen Rodrigues de Oliveira}
\fancyfoot[R]{\thepage}

\begin{document}

\docTitle{Chapitre 2 : Formes linéaires et dualité}

\section{Formes linéaires et hyperplan}

\reminder{
    $E$ et $F$ des $\mathbb{K}$-espaces vectoriels.
    On note $\mathcal{L}(E,F)$ l'ensemble des applications linéaires de $E$ dans $F$.
}

\remark{On note $dim_\mathbb{K}(E)$ la dimension de $E$ en tant qu'espace vectoriel sur $\mathbb{K}$. C'est utile, car par exemple $dim_\mathbb{R}(\mathbb{C}) = 2$ mais $dim_\mathbb{C}(\mathbb{C}) = 1$.}

\definition{
    Soit $E$ un $\mathbb{K}$-espace vectoriel.\\
    On appelle \textbf{forme linéaire} sur $E$ toute application linéaire de $E$ dans $\mathbb{K}$.\\\\
    
    On appelle l'espace dual de $E$ et on note $E^*$ l'ensemble des formes linéaires sur $E$ :
    \[E^* = \mathcal{L}(E, \mathbb{K})\]
}

\remark{Si $\varphi \in E^*$ et $x \in E$, on peut noter $\varphi(x) = \langle \varphi, x \rangle$.}
\vocabulary{On appelle $\langle, \rangle$ le crochet de dualité.}

\example{$E = \mathbb{R}^3$.\\
On pose $f(x,y,z) = 3x + 2y - z$. Alors $f \in E^*$.}

\theorem{Proposition}{}{false}{
    L'image d'un élément de $E^*$ est $\mathbb{K}$ ou $\{0\}$ et $dim_\mathbb{K}(\mathbb{K}) = 1$.\\\\
    \textit{
        $Im(f) = \{0\} \Leftrightarrow f = 0$.
    }
}

\noindent{\textbf{Preuve :} Appliquer le théorème du rang.}

\definition{
    Soit $E$ un $\mathbb{K}$-espace vectoriel.\\
    On appelle \textbf{hyperplan} de $E$ le noyau d'une forme linéaire non nulle sur $E$.
}

\theorem{Proposition}{}{false}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel et soit $H$ un sous-espace vectoriel de $E$.\\
    $H$ est un hyperplan de $E$ $\Leftrightarrow$ $\exists x_0 \in E \setminus \{0\}$ tel que $E = H \oplus Vect(x_0)$.\\\\
    De plus, si $dim(E)=n$, $H$ est un hyperplan de $E$ $\Leftrightarrow$ $dim(H) = n-1$.
}
\remark{Le prof a noté $\mathbb{K}x_0$ au lieu de $Vect(x_0)$.}

\noindent{\textbf{Démonstration :}\\
Supposons que $H$ est un hyperplan de $E$.\\
Par définition, il existe $f \in E^* \setminus \{0\}$ tel que $H = Ker(f)$.\\\\
Soit $x_0 \in E$ tel que $f(x_0) \neq 0$. En particulier, $f(x_0) \neq 0$ (car $f$ est non nulle).\\
Montrons que $E = H \oplus Vect(x_0)$.\\
Soit $x \in H \cup Vect(x_0)$.\\
Comme $x \in Vect(x_0)$, il existe $\lambda \in \mathbb{K}$ tel que $x = x_0 * \lambda$.\\
Or $x \in H \Rightarrow 0 = f(x) = f(x_0 * \lambda) = \lambda f(x_0)$.\\
Comme $f(x_0) \neq 0$, on en déduit que $\lambda = 0$ et donc $x = 0$ et $H \cap Vect(x_0) = \{0\}$.\\\\

Montrons que $E = H + Vect(x_0)$.\\
Soit $x \in E$.\\
On a $x = \underbrace{x - \frac{f(x)}{f(x_0)} x_0}_{\in H} + \underbrace{\frac{f(x)}{f(x_0)} x_0}_{\in Vect(x_0)}$.\\
Donc $E = H + Vect(x_0)$ et finalement $E = H \oplus Vect(x_0)$.\\\\

Réciproquement, supposons qu'il existe $x_0 \in E \setminus \{0\}$ tel que $E = H \oplus Vect(x_0)$.\\
Soit $p$ la projection sur $Vect(x_0)$ parallèlement à $H$. \textit{(ie. pour $x \in E$, $p(x)$ est l'unique élément $\lambda x_0$ dans la décomposition $x = h + \lambda x_0$ avec $h \in H$ et $\lambda \in \mathbb{K}$)}.\\
Pour $x \in E$, on note $\lambda(x) \in \mathbb{K}$ tel que $p(x) = \lambda(x) x_0$.\\
On a $\lambda : E \to \mathbb{K} \in E^*$ (il suffit de montrer que $\lambda$ est linéaire).\\
De plus, $\lambda(x_0) = 1$ par définition donc $\lambda \in E^* \setminus \{0\}$ et $\forall h \in H, \lambda(h) = 0$ (car $p(h) = 0$).\\
Doc $H = Ker(\lambda)$, c'est-à-dire que $H$ est un hyperplan de $E$. $\Box$}

\theorem{Proposition}{}{false}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel et soient $f,g \in E^*$.\\
    \[ker(f) = ker(g) \Leftrightarrow \exists \lambda \in \mathbb{K} \setminus \{0\}, g = \lambda f\] \textit{(ie. $f$ et $g$ sont proportionnelles).}
}

\noindent{\textbf{Démonstration :}\\
    Comme $f$ et $g$ sont non nulles, $ker(f)=ker(g)$ est un hyperplan de $E$.\\
    Donc $E$ s'écrit comme $E = H \oplus Vect(x_0)$ avec $H = ker(f) = ker(g)$ et $x_0 \in E \setminus \{0\}$.\\\\
    En particulier, $x_0 \notin ker(f)$ et $x_0 \notin ker(g)$. (car sinon $E = ker(f)$ ou $E = ker(g)$ et donc $f=0$ ou $g=0$).\\\\
    Donc posons $\lambda = \frac{f(x_0)}{g(x_0)}$.\\
    Montrons que $f = \lambda g$.\\
    Soit $x \in E$.\\
    On écrit $x = h + \mu x_0$ avec $h \in H$ et $\mu \in \mathbb{K}$.\\
    Alors $f(x) = f(h + \mu x_0) = f(h) + \mu f(x_0) = \mu f(x_0)$ (car $h \in H = ker(f)$).\\
    Et de même $g(x) = g(h + \mu x_0) = g(h) + \mu g(x_0) = \mu g(x_0) = \mu \frac{f(x_0)}{\lambda}$.\\\\
    Donc $f = \lambda g$. $\Box$
}

\section{Bases duales}

\subsection{Définition et exemples}

\theorem{Proposition}{Dimension de l'espace dual}{true}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie $n$.
    Alors $dim(E^*) = dim_{\mathbb{K}}(E) \cdot dim_{\mathbb{K}}(\mathbb{K}) = n \cdot 1 = n$.
}

\definition{
    Soit $(e_1, e_2, \ldots, e_n)$ une base de $E$.\\
    On appelle $(e_1^*, e_2^*, \ldots, e_n^*)$ la base duale de $E$ définie par :
    \[\forall i,j \in \{1, 2, \ldots, n\} \text{, } \langle e_i^*, e_j \rangle = \delta_{ij} = \begin{cases}
        1 & \text{si } i=j\\
        0 & \text{sinon}
    \end{cases}\]

    De manière équivalente, si $x \in E$ s'écrit $x = \sum_{j=1}^n x_j e_j$ (coordonnées de $x$ dans la base $(e_1, \ldots, e_n)$), alors :
    $\langle e_i^*, x \rangle = x_i$. (car $\langle e_i^*, \sum_{j=1}^n x_j e_j \rangle = \sum_{j=1}^n x_j \langle e_i^*, e_j \rangle = x_i$)\\

    Ou encore $x = \sum_{j=1}^n \langle e_j^*, x \rangle e_j$.
}

\noindent{\textbf{Preuve de pourquoi est-ce une base :}\\

Montrons que $(e_1^*, e_2^*, \ldots, e_n^*)$ est une base de $E^*$.\\
Comme il y a $n$ vecteurs dans cette famille, il suffit de montrer que cette famille est libre.\\\\

Soit $\lambda_1, \lambda_2, \ldots, \lambda_n \in \mathbb{K}$ tels que $\sum_{i=1}^n \lambda_i e_i^* = 0_{E^*}$.\\
Montrons que tous les $\lambda_i$ sont nuls.\\\\
On applique en $e_j$ l'application linéaire $\sum_{i=1}^n \lambda_i e_i^*$ :
\[\left(\sum_{i=1}^n \lambda_i e_i^*\right)(e_j) = \sum_{i=1}^n \lambda_i \langle e_i^*, e_j \rangle = \lambda_j = 0\]
Donc la famille est libre et c'est bien une base de $E^*$. $\Box$
}

\example{
    Dans $\mathbb{R}^n$, soit $(e_1, \ldots, e_n)$ la base canonique.\\
    Notons $(e_1^*, \ldots, e_n^*)$ sa base duale (canonique).\\
    On a : $\forall i \in \{1, \ldots, n\}, \langle e_i^*, (x_1, \ldots, x_n) \rangle = x_i$.\\
    C'est à dire, $e_i^* : \mathbb{R}^n \to \mathbb{R}, (x_1, \ldots, x_n) \mapsto x_i$.
}

\remark{C'est un fait général, $(e_1^*, \ldots, e_n^*)$ est la base de $E^*$ telle que chaque $e_i^*$ extrait la $i$-ième coordonnée dans la base $(e_1, \ldots, e_n)$.}

\subsection{Représentation matricielle}

Soit $(e_1, \ldots, e_n)$ une base de $E$ et $(e_1^*, \ldots, e_n^*)$ sa base duale.\\
Soit $x \in E$ et $\varphi \in E^*$.\\
On écrit $x = \sum_{i=1}^n x_i e_i$ et $\varphi = \sum_{i=1}^n y_i e_i^*$.\\

\noindent Alors : $\langle \varphi, x \rangle = \left\langle \sum_{i=1}^n y_i e_i^*, \sum_{j=1}^n x_j e_j \right\rangle = \sum_{i=1}^n y_i \langle e_i^*, \sum_{j=1}^n x_j e_j \rangle = \sum_{i=1}^n \sum_{j=1}^n y_i x_j \langle e_i^*, e_j \rangle = \sum_{i=1}^n \sum_{j=1}^n y_i x_j \delta_{ij} = \sum_{i=1}^n y_i x_i$.\\

\noindent Autrement dit, si on pose $X = \begin{pmatrix}
    x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}$ et $Y = \begin{pmatrix}
    y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}$, on a :
\[\langle \varphi, x \rangle = { }^t Y X\]

\theorem{Résumé}{}{true}{
    \[\langle \varphi, x \rangle = \sum_{i=1}^n y_i x_i\]
    Ou encore, si on pose $X = \begin{pmatrix}
        x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}$ et $Y = \begin{pmatrix}
        y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}$, on a :
    \[\langle \varphi, x \rangle = { }^t Y X\]
}

\subsection{Pratique : Calcul de bases duales}

Soit $B = (u_1, u_2, \ldots, u_n)$ une base de $\mathbb{R}^n$ et $B_C = (e_1, e_2, \ldots, e_n)$ la base canonique de $\mathbb{R}^n$.\\
Soit $B^* = (u_1^*, u_2^*, \ldots, u_n^*)$ la base duale de $(u_1, u_2, \ldots, u_n)$ et $B_C^* (e_1^*, e_2^*, \ldots, e_n^*)$ la base duale de $(e_1, e_2, \ldots, e_n)$.\\

\noindent Notons $A$ la matrice des coefficients de la base $(u_1, u_2, \ldots, u_n)$ dans la base $(e_1, e_2, \ldots, e_n)$.\\
On écrit $u_j = \begin{pmatrix}
    a_{1j} \\ a_{2j} \\ \vdots \\ a_{nj} \end{pmatrix}$ pour $j \in \{1, 2, \ldots, n\}$.\\
Alors $A$ est la matrice de passage de la base $B_C$ à la base $B$.\\
On note également $P$ la matrice de passage de la base $B_C^*$ à la base $B^*$.\\
\textit{ie} $u_i^* = \sum_{j=1}^n p_{ji} e_j^*$ pour $i \in \{1, 2, \ldots, n\}$. ($= (p_{1i}, p_{2i}, \ldots, p_{ni})$ dans la base canonique de $(\mathbb{R}^n)^*$).\\

Question : peut-on calculer $P$ à partir de $A$ ?\\
$\delta_ij = \langle u_i^*, u_j \rangle$ (par définition de la base duale).
$= \langle \sum_{k=1}^n p_{ki} e_k^*, \sum_{l=1}^n a_{lj} e_l \rangle = \sum_{k=1}^n \sum_{l=1}^n p_{ki} a_{lj} \langle e_k^*, e_l \rangle = \sum_{k=1}^n p_{ki} a_{kj}$.\\

\textit{(non lisible au tableau depuis ma place, cf. Laurent)}

\theorem{Proposition}{Relation entre matrices de passage}{false}{
    ${ }^t P A = I_n$ c'est-à-dire $P = ({ }^t A)^{-1}$.
}

\example{
    Soit $u_1 = { }^t (1 1)$ et $u_2 = { }^t (-1 2)$.\\
    La matrice de passage de la base canonique à $(u_1, u_2)$ est $A = \begin{pmatrix}
        1 & -1 \\ 1 & 2
    \end{pmatrix}$.\\
    $A^{-1} = \frac{1}{3} \begin{pmatrix}
        2 & 1 \\ -1 & 1
    \end{pmatrix}$.\\
    Donc la matrice de passage de la base duale canonique à la base duale de $(u_1, u_2)$ est $P = { }^t (A^{-1}) = \frac{1}{3} \begin{pmatrix}
        2 & -1 \\ 1 & 1
    \end{pmatrix}$.\\\\
    Donc $u_1^* = \frac{1}{3} (2 e_1^* + e_2^*)$ et $u_2^* = \frac{1}{3} (-e_1^* + e_2^*)$.
    Donc $\langle u_1^*, { }^t (x y) \rangle = \frac{2x + y}{3}$ et $\langle u_2^*, { }^t (x y) \rangle = \frac{-x + y}{3}$.
}

\section{Bases antéduales}

\definition{
    Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie $n$.\\
    Soit $f$ une base de $E^*$.\\
    Une \textbf{base antéduale} notée $e$ de $E$ est telle que $e^* = f$.
}

\theorem{Théorème}{}{false}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie $n$.\\
    Soit $f = (f_1, f_2, \ldots, f_n)$ une base de $E^*$.\\
    Il existe une unique base antéduale de $f$.
}

\theorem{Lemme de séparation}{}{false}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie $n$.\\
    Soit $f=(f_1, f_2, \ldots, f_n)$ une base de $E^*$ et $x \in E$.
    Alors $\forall i \in \{1, 2, \ldots, n\}, \langle f_i, x \rangle = 0 \Rightarrow x = 0$.
}

\noindent{\textbf{Démonstration du lemme de séparation :}\\
    On suppose que $\forall i \in \{1, 2, \ldots, n\}, \langle f_i, x \rangle = 0$.\\
    Comme $f$ base de $E^*$, on a $\forall \varphi \in E^*, \langle \varphi, x \rangle = 0$.\\
    Supposons par l'absurde que $x \neq 0$.\\
    Soit $H$ un supplémentaire de $Vect(x)$ dans $E$.\\
    Alors $E = H \oplus Vect(x)$ et $H$ est un hyperplan de $E$ (\textit{ie $dim(H) = n - 1$}).\\
    $\exists \varphi \in E^* \setminus \{0\}$ tel que $H = Ker(\varphi)$.\\

    Comme $E = H \oplus Vect(x)$, $x \notin H$ donc $\langle \varphi, x \rangle \neq 0$.\\
    Contradiction. Donc $x = 0$. $\Box$
}

\noindent{\textbf{Démonstration du théorème :}\\
\textbf{Unicité :}\\
Soient $e = (e_1, e_2, \ldots, e_n)$ et $e' = (e_1', e_2', \ldots, e_n')$ deux bases antéduales de $f$.\\
Montrons que $e = e'$.\\\\

On a $e^* = (e')^* = f$.\\
En particulier, $f_i(e_j) = \delta_{ij} = f_i(e_j')$ pour tous $i,j \in \{1, 2, \ldots, n\}$.\\
Soit $j \in \{1, 2, \ldots, n\}$.\\
On a $\forall i \in \{1, 2, \ldots, n\}, f_i(e_j - e_j') = 0$.\\
Donc par le lemme de séparation, $e_j - e_j' = 0$ c'est-à-dire $e_j = e_j'$.\\\\

\textbf{Existence :}\\
Notons $E^{**} = (E^*)^*$ (l'espace bidual de $E$).\\
Soit $J : E \to E^{**}$ l'application définie par : $J \colon x \mapsto (\varphi \mapsto \langle \varphi, x \rangle)$.\\
$J$ est linéaire, montrons qu'elle est injective.\\\\
Soit $x \in ker(J)$, donc $ev_x = 0_{E^{**}}$.\\
Alors $\forall \varphi \in E^*, \langle \varphi, x \rangle = 0$.\\
Donc par le lemme de séparation, $x = 0$.\\
Donc $ker(J) = \{0\}$ et $J$ est injective.\\\\

Comme $dim(E) = dim(E^{**}) = n < +\infty$ et que $J$ est injective, $J$ est un isomorphisme.\\\\
Donc $J$ est surjective.\\
Donc $J$ est bijective.\\\\

La base antéduale $(e_1, \ldots, e_n)$ est alors définie comme $(J^{-1}(f_1^*), \ldots, J^{-1}(f_n^*))$. $\Box$
}
\end{document}