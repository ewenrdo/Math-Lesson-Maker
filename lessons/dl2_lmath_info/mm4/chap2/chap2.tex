\documentclass{article}

\usepackage[a4paper, left=1.5cm, right=1.5cm, top=2cm, bottom=2cm]{geometry}

\usepackage{../../../../components/components}

\usepackage{fancyhdr}


% Configuration des en-têtes et pieds de page
\pagestyle{fancy}
\fancyhf{} % reset tout

\fancyhead[L]{DL2 Math-Info MM4}
\fancyhead[C]{Algèbre linéaire}
\fancyhead[R]{2025-2026}

\fancyfoot[L]{Ewen Rodrigues de Oliveira}
\fancyfoot[R]{\thepage}

\begin{document}

\docTitle{Chapitre 2 : Formes linéaires et dualité}

\section{Formes linéaires et hyperplan}

\reminder{
    $E$ et $F$ des $\mathbb{K}$-espaces vectoriels.
    On note $\mathcal{L}(E,F)$ l'ensemble des applications linéaires de $E$ dans $F$.
}

\remark{On note $dim_\mathbb{K}(E)$ la dimension de $E$ en tant qu'espace vectoriel sur $\mathbb{K}$. C'est utile, car par exemple $dim_\mathbb{R}(\mathbb{C}) = 2$ mais $dim_\mathbb{C}(\mathbb{C}) = 1$.}

\definition{
    Soit $E$ un $\mathbb{K}$-espace vectoriel.\\
    On appelle \textbf{forme linéaire} sur $E$ toute application linéaire de $E$ dans $\mathbb{K}$.\\\\
    
    On appelle l'espace dual de $E$ et on note $E^*$ l'ensemble des formes linéaires sur $E$ :
    \[E^* = \mathcal{L}(E, \mathbb{K})\]
}

\remark{Si $\varphi \in E^*$ et $x \in E$, on peut noter $\varphi(x) = \langle \varphi, x \rangle$.}
\vocabulary{On appelle $\langle, \rangle$ le crochet de dualité.}

\example{$E = \mathbb{R}^3$.\\
On pose $f(x,y,z) = 3x + 2y - z$. Alors $f \in E^*$.}

\theorem{Proposition}{}{false}{
    L'image d'un élément de $E^*$ est $\mathbb{K}$ ou $\{0\}$ et $dim_\mathbb{K}(\mathbb{K}) = 1$.\\\\
    \textit{
        $Im(f) = \{0\} \Leftrightarrow f = 0$.
    }
}

\noindent{\textbf{Preuve :} Appliquer le théorème du rang.}

\definition{
    Soit $E$ un $\mathbb{K}$-espace vectoriel.\\
    On appelle \textbf{hyperplan} de $E$ le noyau d'une forme linéaire non nulle sur $E$.
}

\theorem{Proposition}{}{false}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel et soit $H$ un sous-espace vectoriel de $E$.\\
    $H$ est un hyperplan de $E$ $\Leftrightarrow$ $\exists x_0 \in E \setminus \{0\}$ tel que $E = H \oplus Vect(x_0)$.\\\\
    De plus, si $dim(E)=n$, $H$ est un hyperplan de $E$ $\Leftrightarrow$ $dim(H) = n-1$.
}
\remark{Le prof a noté $\mathbb{K}x_0$ au lieu de $Vect(x_0)$.}
\ndlr{On pourrait avoir aussi : $\forall x \in E \setminus H, E = H \oplus Vect(x)$.}
\noindent{\textbf{Démonstration :}\\
Supposons que $H$ est un hyperplan de $E$.\\
Par définition, il existe $f \in E^* \setminus \{0\}$ tel que $H = Ker(f)$.\\\\
Soit $x_0 \in E$ tel que $f(x_0) \neq 0$. En particulier, $f(x_0) \neq 0$ (car $f$ est non nulle).\\
Montrons que $E = H \oplus Vect(x_0)$.\\
Soit $x \in H \cup Vect(x_0)$.\\
Comme $x \in Vect(x_0)$, il existe $\lambda \in \mathbb{K}$ tel que $x = x_0 * \lambda$.\\
Or $x \in H \Rightarrow 0 = f(x) = f(x_0 * \lambda) = \lambda f(x_0)$.\\
Comme $f(x_0) \neq 0$, on en déduit que $\lambda = 0$ et donc $x = 0$ et $H \cap Vect(x_0) = \{0\}$.\\\\

Montrons que $E = H + Vect(x_0)$.\\
Soit $x \in E$.\\
On a $x = \underbrace{x - \frac{f(x)}{f(x_0)} x_0}_{\in H} + \underbrace{\frac{f(x)}{f(x_0)} x_0}_{\in Vect(x_0)}$.\\
Donc $E = H + Vect(x_0)$ et finalement $E = H \oplus Vect(x_0)$.\\\\

Réciproquement, supposons qu'il existe $x_0 \in E \setminus \{0\}$ tel que $E = H \oplus Vect(x_0)$.\\
Soit $p$ la projection sur $Vect(x_0)$ parallèlement à $H$. \textit{(ie. pour $x \in E$, $p(x)$ est l'unique élément $\lambda x_0$ dans la décomposition $x = h + \lambda x_0$ avec $h \in H$ et $\lambda \in \mathbb{K}$)}.\\
Pour $x \in E$, on note $\lambda(x) \in \mathbb{K}$ tel que $p(x) = \lambda(x) x_0$.\\
On a $\lambda : E \to \mathbb{K} \in E^*$ (il suffit de montrer que $\lambda$ est linéaire).\\
De plus, $\lambda(x_0) = 1$ par définition donc $\lambda \in E^* \setminus \{0\}$ et $\forall h \in H, \lambda(h) = 0$ (car $p(h) = 0$).\\
Doc $H = Ker(\lambda)$, c'est-à-dire que $H$ est un hyperplan de $E$. $\Box$}

\theorem{Proposition}{}{false}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel et soient $f,g \in E^*$.\\
    \[ker(f) = ker(g) \Leftrightarrow \exists \lambda \in \mathbb{K} \setminus \{0\}, g = \lambda f\] \textit{(ie. $f$ et $g$ sont proportionnelles).}
}

\noindent{\textbf{Démonstration :}\\
    Comme $f$ et $g$ sont non nulles, $ker(f)=ker(g)$ est un hyperplan de $E$.\\
    Donc $E$ s'écrit comme $E = H \oplus Vect(x_0)$ avec $H = ker(f) = ker(g)$ et $x_0 \in E \setminus \{0\}$.\\\\
    En particulier, $x_0 \notin ker(f)$ et $x_0 \notin ker(g)$. (car sinon $E = ker(f)$ ou $E = ker(g)$ et donc $f=0$ ou $g=0$).\\\\
    Donc posons $\lambda = \frac{f(x_0)}{g(x_0)}$.\\
    Montrons que $f = \lambda g$.\\
    Soit $x \in E$.\\
    On écrit $x = h + \mu x_0$ avec $h \in H$ et $\mu \in \mathbb{K}$.\\
    Alors $f(x) = f(h + \mu x_0) = f(h) + \mu f(x_0) = \mu f(x_0)$ (car $h \in H = ker(f)$).\\
    Et de même $g(x) = g(h + \mu x_0) = g(h) + \mu g(x_0) = \mu g(x_0) = \mu \frac{f(x_0)}{\lambda}$.\\\\
    Donc $f = \lambda g$. $\Box$
}

\section{Bases duales}

\subsection{Définition et exemples}

\theorem{Proposition}{Dimension de l'espace dual}{true}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie $n$.
    Alors $dim(E^*) = dim_{\mathbb{K}}(E) \cdot dim_{\mathbb{K}}(\mathbb{K}) = n \cdot 1 = n$.
}

\definition{
    Soit $(e_1, e_2, \ldots, e_n)$ une base de $E$.\\
    On appelle $(e_1^*, e_2^*, \ldots, e_n^*)$ la base duale de $E$ définie par :
    \[\forall i,j \in \{1, 2, \ldots, n\} \text{, } \langle e_i^*, e_j \rangle = \delta_{ij} = \begin{cases}
        1 & \text{si } i=j\\
        0 & \text{sinon}
    \end{cases}\]

    De manière équivalente, si $x \in E$ s'écrit $x = \sum_{j=1}^n x_j e_j$ (coordonnées de $x$ dans la base $(e_1, \ldots, e_n)$), alors :
    $\langle e_i^*, x \rangle = x_i$. (car $\langle e_i^*, \sum_{j=1}^n x_j e_j \rangle = \sum_{j=1}^n x_j \langle e_i^*, e_j \rangle = x_i$)\\

    Ou encore $x = \sum_{j=1}^n \langle e_j^*, x \rangle e_j$.
}

\noindent{\textbf{Preuve de pourquoi est-ce une base :}\\

Montrons que $(e_1^*, e_2^*, \ldots, e_n^*)$ est une base de $E^*$.\\
Comme il y a $n$ vecteurs dans cette famille, il suffit de montrer que cette famille est libre.\\\\

Soit $\lambda_1, \lambda_2, \ldots, \lambda_n \in \mathbb{K}$ tels que $\sum_{i=1}^n \lambda_i e_i^* = 0_{E^*}$.\\
Montrons que tous les $\lambda_i$ sont nuls.\\\\
On applique en $e_j$ l'application linéaire $\sum_{i=1}^n \lambda_i e_i^*$ :
\[\left(\sum_{i=1}^n \lambda_i e_i^*\right)(e_j) = \sum_{i=1}^n \lambda_i \langle e_i^*, e_j \rangle = \lambda_j = 0\]
Donc la famille est libre et c'est bien une base de $E^*$. $\Box$
}

\example{
    Dans $\mathbb{R}^n$, soit $(e_1, \ldots, e_n)$ la base canonique.\\
    Notons $(e_1^*, \ldots, e_n^*)$ sa base duale (canonique).\\
    On a : $\forall i \in \{1, \ldots, n\}, \langle e_i^*, (x_1, \ldots, x_n) \rangle = x_i$.\\
    C'est à dire, $e_i^* : \mathbb{R}^n \to \mathbb{R}, (x_1, \ldots, x_n) \mapsto x_i$.
}

\remark{C'est un fait général, $(e_1^*, \ldots, e_n^*)$ est la base de $E^*$ telle que chaque $e_i^*$ extrait la $i$-ième coordonnée dans la base $(e_1, \ldots, e_n)$.}

\subsection{Représentation matricielle}

\theorem{Proposition}{Couplage en base et lien avec les matrices}{true}{
    Soit $E$ un espace vectoriel de dimension $n$ sur un corps $\mathbb{K}$. 
    Soit $(e_1,\dots,e_n)$ une base de $E$ et $(e_1^*,\dots,e_n^*)$ sa base duale.\\

    Soit $x \in E$ et $\varphi \in E^*$ écrits sous la forme
    \[
        x = \sum_{i=1}^n x_i e_i
        \qquad\text{et}\qquad
        \varphi = \sum_{i=1}^n y_i e_i^*.
    \]
    Alors 
    \[
        \langle \varphi, x \rangle = \sum_{i=1}^n y_i x_i.
    \]
    De plus, si l'on pose
    \[
        X = \begin{pmatrix}
            x_1 \\ \vdots \\ x_n
        \end{pmatrix}
        \qquad\text{et}\qquad
        Y = \begin{pmatrix}
            y_1 \\ \vdots \\ y_n
        \end{pmatrix},
    \]
    on obtient
    \[
        \langle \varphi, x \rangle = {}^tY\,X.
    \]
}

\noindent{\textbf{Démonstration :}\\

Soit $(e_1, \ldots, e_n)$ une base de $E$ et $(e_1^*, \ldots, e_n^*)$ sa base duale.\\
Soit $x \in E$ et $\varphi \in E^*$.\\
On écrit $x = \sum_{i=1}^n x_i e_i$ et $\varphi = \sum_{i=1}^n y_i e_i^*$.\\

\noindent Alors : $\langle \varphi, x \rangle = \left\langle \sum_{i=1}^n y_i e_i^*, \sum_{j=1}^n x_j e_j \right\rangle = \sum_{i=1}^n y_i \langle e_i^*, \sum_{j=1}^n x_j e_j \rangle = \sum_{i=1}^n \sum_{j=1}^n y_i x_j \langle e_i^*, e_j \rangle = \sum_{i=1}^n \sum_{j=1}^n y_i x_j \delta_{ij} = \sum_{i=1}^n y_i x_i$.\\

\noindent Autrement dit, si on pose $X = \begin{pmatrix}
    x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}$ et $Y = \begin{pmatrix}
    y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}$, on a :
\[\langle \varphi, x \rangle = { }^t Y X\]
$\Box$
}

\subsection{Pratique : Calcul de bases duales}

\definition{
    On appelle \textbf{matrice de passage de $B$ vers $C$} la matrice dont les colonnes sont les coordonnées des vecteurs de la base $C$ dans la base $B$.\\
    On la note $P_{B \to C}$.
}

\reminder{
    $A$ est la matrice de passage de $B$ à $B'$ si $e_j' = \sum_{i=1}^n a_{ij} \cdot e_i$.
}

\reminder{On a la relation suivante par rapport aux coordonnées : $X_B = P_{B \to C} X_C$.}

\theorem{Proposition}{Relation entre matrices de passage}{false}{
    On a $({ }^t P_{B_C^* \to B^*}) P_{B_C \to B} = I_n$ et donc $P_{B_C^* \to B^*} = ({ }^t P_{B_C \to B})^{-1}$.\\\\
    \textit{Avec les notations de la démonstration : ${ }^t P A = I_n$ c'est-à-dire $P = ({ }^t A)^{-1}$.}
}

\noindent{\textbf{Démonstration :}\\
Soit $B = (u_1, u_2, \ldots, u_n)$ une base de $\mathbb{R}^n$ et $B_C = (e_1, e_2, \ldots, e_n)$ la base canonique de $\mathbb{R}^n$.\\
Soit $B^* = (u_1^*, u_2^*, \ldots, u_n^*)$ la base duale de $(u_1, u_2, \ldots, u_n)$ et $B_C^* (e_1^*, e_2^*, \ldots, e_n^*)$ la base duale de $(e_1, e_2, \ldots, e_n)$.\\

\noindent Notons $A$ la matrice des coefficients de la base $(u_1, u_2, \ldots, u_n)$ dans la base $(e_1, e_2, \ldots, e_n)$.\\
On écrit $u_j = \begin{pmatrix}
    a_{1j} \\ a_{2j} \\ \vdots \\ a_{nj} \end{pmatrix}$ pour $j \in \{1, 2, \ldots, n\}$.\\
Alors $A$ est la matrice de passage de la base $B_C$ à la base $B$.\\
On note également $P$ la matrice de passage de la base $B_C^*$ à la base $B^*$.\\
\textit{ie} $u_i^* = \sum_{j=1}^n p_{ji} e_j^*$ pour $i \in \{1, 2, \ldots, n\}$. ($= (p_{1i}, p_{2i}, \ldots, p_{ni})$ dans la base canonique de $(\mathbb{R}^n)^*$).\\

Question : peut-on calculer $P$ à partir de $A$ ?\\
$\delta_ij = \langle u_i^*, u_j \rangle$ (par définition de la base duale).
$= \langle \sum_{k=1}^n p_{ki} e_k^*, \sum_{l=1}^n a_{lj} e_l \rangle = \sum_{k=1}^n \sum_{l=1}^n p_{ki} a_{lj} \langle e_k^*, e_l \rangle = \sum_{k=1}^n p_{ki} a_{kj}$.\\

Donc la matrice $I_n$ est égale à la matrice produit ${ }^t P A$. \\
Donc ${ }^t P A = I_n$ c'est-à-dire $P = ({ }^t A)^{-1}$. $\Box$
}


\example{
    Soit $u_1 = { }^t (1 \: 1)$ et $u_2 = { }^t (-1 \: 2)$.\\
    La matrice de passage de la base canonique à $(u_1, u_2)$ est $A = \begin{pmatrix}
        1 & -1 \\ 1 & 2
    \end{pmatrix}$.\\
    $A^{-1} = \frac{1}{3} \begin{pmatrix}
        2 & 1 \\ -1 & 1
    \end{pmatrix}$.\\
    Donc la matrice de passage de la base duale canonique à la base duale de $(u_1, u_2)$ est $P = { }^t (A^{-1}) = \frac{1}{3} \begin{pmatrix}
        2 & -1 \\ 1 & 1
    \end{pmatrix}$.\\\\
    Donc $u_1^* = \frac{1}{3} (2 e_1^* + e_2^*)$ et $u_2^* = \frac{1}{3} (-e_1^* + e_2^*)$.
    Donc $\langle u_1^*, { }^t (x y) \rangle = \frac{2x + y}{3}$ et $\langle u_2^*, { }^t (x y) \rangle = \frac{-x + y}{3}$.
}

\section{Bases antéduales}

\definition{
    Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie $n$.\\
    Soit $f$ une base de $E^*$.\\
    Une \textbf{base antéduale} notée $e$ de $E$ est telle que $e^* = f$.
}

\theorem{Théorème}{}{false}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie $n$.\\
    Soit $f = (f_1, f_2, \ldots, f_n)$ une base de $E^*$.\\
    Il existe une unique base antéduale de $f$.
}

\theorem{Lemme de séparation}{}{false}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie $n$.\\
    On a que $\forall \varphi \in E^*, \langle \varphi, x \rangle = 0 \Rightarrow x = 0$.\\
    
    En particulier, soit $f=(f_1, f_2, \ldots, f_n)$ une base de $E^*$ et $x \in E$.
    Alors, $\forall i \in \{1, 2, \ldots, n\}, \langle f_i, x \rangle = 0 \Rightarrow x = 0$.
}

\noindent{\textbf{Démonstration du lemme de séparation :}\\
    On suppose que $\forall i \in \{1, 2, \ldots, n\}, \langle f_i, x \rangle = 0$.\\
    Comme $f$ base de $E^*$, on a $\forall \varphi \in E^*, \langle \varphi, x \rangle = 0$.\\
    Supposons par l'absurde que $x \neq 0$.\\
    Soit $H$ un supplémentaire de $Vect(x)$ dans $E$.\\
    Alors $E = H \oplus Vect(x)$ et $H$ est un hyperplan de $E$ (\textit{ie $dim(H) = n - 1$}).\\
    $\exists \varphi \in E^* \setminus \{0\}$ tel que $H = Ker(\varphi)$.\\

    Comme $E = H \oplus Vect(x)$, $x \notin H$ donc $\langle \varphi, x \rangle \neq 0$.\\
    Contradiction. Donc $x = 0$. $\Box$
}

\noindent{\textbf{Démonstration du théorème :}\\
\textbf{Unicité :}\\
Soient $e = (e_1, e_2, \ldots, e_n)$ et $e' = (e_1', e_2', \ldots, e_n')$ deux bases antéduales de $f$.\\
Montrons que $e = e'$.\\\\

On a $e^* = (e')^* = f$.\\
En particulier, $f_i(e_j) = \delta_{ij} = f_i(e_j')$ pour tous $i,j \in \{1, 2, \ldots, n\}$.\\
Soit $j \in \{1, 2, \ldots, n\}$.\\
On a $\forall i \in \{1, 2, \ldots, n\}, f_i(e_j - e_j') = 0$.\\
Donc par le lemme de séparation, $e_j - e_j' = 0$ c'est-à-dire $e_j = e_j'$.\\\\

\textbf{Existence :}\\
Notons $E^{**} = (E^*)^*$ (l'espace bidual de $E$).\\
Soit $J : E \to E^{**}$ l'application définie par : $J \colon x \mapsto \underbrace{(\varphi \mapsto \langle \varphi, x \rangle)}_{ev_x \in E^{**}}$.\\\\
$J$ est linéaire, montrons qu'elle est injective.\\\\
Soit $x \in ker(J)$, donc $ev_x = 0_{E^{**}}$.\\
Alors $\forall \varphi \in E^*, \langle \varphi, x \rangle = 0$.\\
Donc par le lemme de séparation, $x = 0$.\\
Donc $ker(J) = \{0\}$ et $J$ est injective.\\\\

Comme $dim(E) = dim(E^{**}) = n < +\infty$ et que $J$ est injective, $J$ est un isomorphisme \textit{(théorème du rang)}.
On pose $e_i = J^{-1}(f_i^{*})$ où $\underbrace{(f_1^{*}, f_2^{*}, \ldots, f_n^{*})}_{\text{base de $E^{**}$}}$ est la base duale de $f = (f_1, f_2, \ldots, f_n)$.\\\\
Montrons que $e^* = f$.\\\\
Soit $1 \leq i,j \leq n$.\\
On a $\langle f_i, e_j \rangle = ev_{e_j}(f_i) = \langle J(e_j), f_i \rangle = \langle J(J^{-1}(f_j^{*})), f_i \rangle = \langle f_j^{*}, f_i \rangle = \delta_{ij}$.\\\\
Donc $f$ est la base duale de $e$, \textit{i.e.} $e^* = f$. $\Box$
}

\remark{On a déjà vu qu'en pratique on peut calculer des bases duales. 
On suppose qu'on connaît $B$ (base de $E$) et $B^*$ (base de $E^*$) et on veut calculer la base duale de $B'$.
On note $A = P_{B \to B'}$ la matrice de passage de $B$ à $B'$.
Et on note $P = P_{B^* \to (B')^*}$ la matrice de passage de $B^*$ à $(B')^*$.\\
On a vu que $P = ({ }^t A)^{-1}$.\\\\
Une autre preuve de l'existence des bases antéduales est la suivante :\\
Étant donné une base $f$ de $E^*$, on veut construire sa base antéduale $e$.\\\\
Soit $B$ une base quelconque de $E$ et $B^*$ sa base duale.\\
Soit $P$ la matrice de passage de $B^*$ à $f$.\\
On pose $e_j = \sum_{i=1}^n c_{ij} \cdot \varepsilon_i$ où $\varepsilon_i$ sont les vecteurs de la base $B$ et $C = (c_{ij})$ la matrice de passage de $B$ à $e$.\\\\

\begin{center}
    \includegraphics[width=0.25\textwidth]{./images/graph_chap2_1.png}
    \captionof{figure}{Construction d'une base antéduale.}
\end{center}
\textit{Synthèse :} Montrons que $\langle f_j, e_i \rangle = \delta_{ij}$.\\
On a $f_j = \sum_{i=1}^n p_{ij} \cdot \varepsilon_i^*$ où $\varepsilon_i^*$ sont les vecteurs de la base $B^*$.\\
De plus, on a $e_j = \sum_{i=1}^n c_{ij} \cdot \varepsilon_i$.\\\\
D'où : $\langle f_j, e_i \rangle = \left\langle \sum_{k=1}^n p_{kj} \cdot \varepsilon_k^*, \sum_{l=1}^n c_{li} \cdot \varepsilon_l \right\rangle = \sum_{k=1}^n \sum_{l=1}^n p_{kj} c_{li} \langle \varepsilon_k^*, \varepsilon_l \rangle = \sum_{k=1}^n p_{kj} c_{ki} = \delta_{ij}$ car ${ }^t P C = I_n$.\\
Donc $e$ est bien la base antéduale de $f$. $Box$
}

\example{On pose $f_1(x,y) = 3x-y$ et $f_2(x,y)=x+2y$.\\
Déterminons la base antéduale de $(f_1, f_2)$ dans $\mathbb{R}^2$.\\\\
On pose $A := P_{B_C^* \to f} = \begin{pmatrix}
    3 & 1 \\ -1 & 2
\end{pmatrix}$ la matrice dont les colonnes sont les coordonnées de $f_1$ et $f_2$ dans la base duale canonique. (ie. la matrice de passage de la base duale canonique à la base $(f_1, f_2)$).\\\\
On a : $A^{-1} = \frac{1}{7} \begin{pmatrix}
    2 & -1 \\ 1 & 3
\end{pmatrix}$.\\
On a que $({ }^t A)^{-1} = \frac{1}{7} \begin{pmatrix}
    2 & 1 \\ -1 & 3
\end{pmatrix}$.
Donc la base antéduale de $(f_1, f_2)$ est donnée par : $(\begin{pmatrix}
    2/7 \\ -1/7
\end{pmatrix}, \begin{pmatrix}1/7 \\ 3/7
\end{pmatrix})$.
}

\section{Application aux systèmes linéaires}
\remark{
    Le système linéaire suivant est une droite en tant qu'intersection d'hyperplans qui sont des noyaux de formes linéaires indépendantes :
    \[
    (d_1) : 
    \begin{cases}
        x + 2y - z = 0\\
        2x - y + z = 0
    \end{cases}
    \]
}

\theorem{Proposition}{}{false}{
    Soit $E$ un $\mathbb{K}$-espace vectoriel de dimension finie $n$.\\
    Soient $(\varphi_1, \varphi_2, \ldots, \varphi_k)$ des formes linéaires sur $E$.\\
    Soit $V = \bigcap_{i=1}^k Ker(\varphi_i)$.\\\\
    Si $(\varphi_1, \varphi_2, \ldots, \varphi_k)$ est une famille libre dans $E^*$, alors $dim(V) = n - k$.\\
    Plus généralement, si $k' = dim(Vect(\varphi_1, \varphi_2, \ldots, \varphi_k))$, alors $dim(V) = n - k'$.
}

\noindent{\textbf{Démonstration :}\\
On suppose que $(\varphi_1, \varphi_2, \ldots, \varphi_k)$ est une famille libre dans $E^*$.\\
Par le théorème de la base incomplète, soit $(\varphi_1, \varphi_2, \ldots, \varphi_k, \varphi_{k+1}, \ldots, \varphi_n)$ une base de $E^*$.\\\\
On pose $F : E \to \mathbb{K}^n, x \mapsto \begin{pmatrix}
    \varphi_1(x) \\ \varphi_2(x) \\ \vdots \\ \varphi_n(x)
\end{pmatrix}$.\\

Montrons que $F$ est un isomorphisme.\\
Il suffit de montrer que $F$ est injective (car $dim(E) = dim(\mathbb{K}^n) = n < +\infty$).\\\\
Soit $x \in E$ tel que $\forall i \in \{1, 2, \ldots, n\}, \varphi_i(x) = 0$.\\
Par le lemme de séparation, $x = 0$.\\
Donc $ker(F) = \{0\}$ et $F$ est injective.\\\\
Donc $F$ est un isomorphisme.\\\\
On a $V = \bigcap_{i=1}^k Ker(\varphi_i) = F^{-1}(\{\begin{pmatrix}
    y_1 \\ y_2 \\ \vdots \\ y_n
\end{pmatrix} \in \mathbb{K}^n \mid \forall 1 \leq i \leq k, y_i = 0\}) = F^{-1}(Vect(\underbrace{e_{k+1}, e_{k+2}, \ldots, e_n}_{\text{de dim } n-k}))$ où $(e_1, e_2, \ldots, e_n)$ est la base canonique de $\mathbb{K}^n$.\\
Comme $F$ est un isomorphisme, $dim(V) = dim(Vect(e_{k+1}, e_{k+2}, \ldots, e_n)) = n - k$.\\\\

Pour le cas général.\\
Soit $(\varphi_1', \varphi_2', \ldots, \varphi_{k'}')$ une base de $Vect(\varphi_1, \varphi_2, \ldots, \varphi_k)$.\\
Alors $V = \bigcap_{i=1}^k Ker(\varphi_i) = \bigcap_{j=1}^{k'} Ker(\varphi_j')$.\\
En effet, $x \in V \Leftrightarrow \forall i \in \{1, 2, \ldots, k\}, \varphi_i(x) = 0 \Leftrightarrow \forall \varphi \in Vect(\varphi_1, \varphi_2, \ldots, \varphi_k), \varphi(x) = 0 \Leftrightarrow \forall \varphi \in \{\varphi_1', \varphi_2', \ldots, \varphi_{k'}'\}, \varphi(x) = 0 \Leftrightarrow \forall i \in \{1, 2, \ldots, k'\}, \varphi_i'(x) = 0 \Leftrightarrow x \in \bigcap_{i=1}^{k'} Ker(\varphi_i')$.\\\\
En appliquant la preuve précédente, on a $dim(V) = n - k'$. $\Box$
}

\example{Reprenons $(d_1)$.\\
On a $E = \mathbb{R}^3$ et $n = 3$.\\
On note $\varphi_1(x,y,z) = x + 2y - z$ et $\varphi_2(x,y,z) = 2x - y + z$.\\
On a $V = Ker(\varphi_1) \cap Ker(\varphi_2)$.\\
On admet que $(\varphi_1, \varphi_2)$ est une famille libre dans $E^*$.\\\\
Donc $dim(V) = 3 - 2 = 1$.\\
Donc $(d_1)$ est une droite dans $\mathbb{R}^3$.
}

\training{On peut montrer plus facilement que le rang des colonnes est égal au rang des lignes en utilisant les formes linéaires.}
\theorem{Théorème}{Rang des lignes et des colonnes}{true}{
    Soit $M \in M_{m,n}(\mathbb{K})$.\\
    Soit $p$ le rang de la famille des vecteurs lignes de $M$ et soit $q$ le rang de la famille des vecteurs colonnes de $M$.\\
    Alors $p = q$.
}

\noindent{\textbf{Démonstration :}\\
    Posons $E = \mathbb{R}^n$.\\
    Soit $(f_1, \ldots, f_m)$ les formes linéaires sur $E$ qui correspondent aux vecteurs lignes de $M$.\\
    On pose $F : E \to \mathbb{R}^m, x \mapsto \begin{pmatrix}
        f_1(x) \\ f_2(x) \\ \vdots \\ f_m(x)
    \end{pmatrix}$.\\\\
    Posons $V = ker(F) = \bigcap_{i=1}^m Ker(f_i)$.\\
    On a par définition $q = rg(F)$.\\
    La proposition précédente donne $dim(V) = n - dim(Vect(f_1, \ldots, f_m)) = n - p$.\\\\
    Par le théorème du rang, on a $dim(E) = dim(ker(F)) + rg(F)$, c'est-à-dire $n = dim(V) + q$.\\\\
    Donc $n = n - p + q$ et finalement $p = q$. $\Box$   
}

\section{Application linéaire transposée}

\definition{
    Soient $E$ et $F$ deux $\mathbb{K}$-espaces vectoriels.\\
    Soit $f \in \mathcal{L}(E,F)$.\\
    On appelle \textbf{application linéaire transposée} de $f$ notée ${ }^t f$ ou $f^{*}$ l'application linéaire $f^t : F^* \to E^*$ définie par :
    \[\forall \varphi \in F^*, f^t(\varphi) = \varphi \circ f\]
    De manière équivalente, $f^{*}$ est l'application qui vérifie $\forall x \in E, \forall \varphi \in F^*, \langle f^{*}(\varphi), x \rangle = \langle \varphi, f(x) \rangle$.
}

\theorem{Proposition}{}{false}{
    Soient $E,F,G$ des $\mathbb{K}$-espaces vectoriels.\\
    Soient $f \in \mathcal{L}(E,F)$ et $g \in \mathcal{L}(F,G)$.\\
    Alors :
    \[(g \circ f)^{*} = f^{*} \circ g^{*}\]
    et : $id_E^{*} = id_{E^*}$.
}

\noindent{\textbf{Démonstration :}\\
On rappelle que $(g \circ f)^{*} : G^* \to E^*$.\\
Soit $\varphi \in G^*$.\\
On a : $(g \circ f)^{*}(\varphi) = \varphi \circ (g \circ f) = (\varphi \circ g) \circ f = f^{*}(\varphi \circ g) = f^{*}(g^{*}(\varphi)) = (f^{*} \circ g^{*})(\varphi)$.\\
Donc ($g \circ f)^{*} = f^{*} \circ g^{*}$.\\

\noindent Pour l'identité, soit $\varphi \in E^*$.\\
On a : $id_E^{*}(\varphi) = \varphi \circ id_E = \varphi = id_{E^*}(\varphi)$.\\
Donc $id_E^{*} = id_{E^*}$. $\Box$
}

\theorem{Proposition}{}{false}{
    Soient $E$ et $F$ des $\mathbb{K}$-espaces vectoriels.\\
    Soient $e$ une base de $E$ et $f$ une base de $F$ et soient $e^*$ et $f^*$ leurs bases duales respectives.\\
    Soit $g \in \mathcal{L}(E,F)$ (alors $g^{*} \in \mathcal{L}(F^*, E^*)$).\\
    Alors : 
    \[Mat_{f^*, e^*}(g^{*}) = { }^t (Mat_{e,f}(g))\]
}
\end{document}